{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Basline_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNdLfo3HHO_f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk4bwiyT2_rS"
      },
      "source": [
        "# Baseline Classifier\n",
        "\n",
        "This notebook implements the baseline classification model using pre-processed training data (with and without lemmatization), and uses the bag of words approach with TF-IDF for vectorization. Finally, it uses Multinomial Naive Bayes Classifier implementation from sklearn to develop the baseline classifier.\n",
        "\n",
        "We program the following steps for developing the baseline model:\n",
        "1. Apply Count Vectorizer\n",
        "2. TF-IDF Transformation\n",
        "3. Apply Multinomial Naive Bayes Classifier on data with and without lemmatization\n",
        "4. Test on test set\n",
        "5. View Accuracy Metrics\n",
        "6. Pickle the models\n",
        "\n",
        "### To do:\n",
        "\n",
        "- [ ] Provide description for all processes and reason to perform them\n",
        "- [ ] Describe Directory Structure\n",
        "- [x] Load Dataset into pandas\n",
        "- [x] Apply Count Vectorizer\n",
        "- [x] TF-IDF Transformation\n",
        "- [x] Apply Multinomial Naive Bayes Classifier on data with and without lemmatization\n",
        "- [x] Test on test set\n",
        "- [x] View Accuracy Metrics\n",
        "- [x] Pickle the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57TK2is-2_r_"
      },
      "source": [
        "### Import Statements and File Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBNtLF-E2_sF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from IPython.display import display, HTML\n",
        "import re\n",
        "import pickle\n",
        "import scipy\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Quora-Data/\"\n",
        "train_csv_with_lemmatization = data_dir + \"pre-processing/train_EDA1_preprocessing_with_lemma_EDA2.csv\"\n",
        "test_csv_with_lemmatization = data_dir + \"pre-processing/test_EDA1_preprocessing_with_lemma_EDA2.csv\"\n",
        "\n",
        "train_csv_without_lemmatization = data_dir + \"pre-processing/train_EDA1_preprocessing_without_lemma_EDA2.csv\"\n",
        "test_csv_without_lemmatization = data_dir + \"pre-processing/test_EDA1_preprocessing_without_lemma_EDA2.csv\"\n",
        "\n",
        "model_with_lemmatization_data = data_dir + \"Models/MultinomialNB_lemmatized_data.sav\"\n",
        "model_without_lemmatization_data = data_dir + \"Models/MultinomialNB_non_lemmatized_data.sav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMqfkGB72_sO"
      },
      "source": [
        "### Load datasets into pandas dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_mYz0hd3VIt",
        "outputId": "10a7933f-5a21-4b4c-d0fb-d60469fa7d4d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXgzTQP_KFO6"
      },
      "source": [
        "def data_loader(list_X, file_Y):\n",
        "    df = pd.read_csv(list_X[0])\n",
        "    for i in range(1, len(list_X)):\n",
        "        df = df.join(pd.read_csv(list_X[i]))\n",
        "    return (df[df.columns.difference(['Y', 'qid1', 'qid', 'qid2', 'id'])], pd.read_csv(file_Y)['Y'])\n",
        "\n",
        "X_train, Y_train = data_loader([\n",
        "                                data_dir + \"pre-processing/features1_2_selected_train.csv\"\n",
        "                    ], \n",
        "                    data_dir + \"pre-processing/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNb7iaxv2_sS",
        "outputId": "14cc0395-fff8-4fb4-d6d0-df71eec0302e"
      },
      "source": [
        "df1 = pd.read_csv(train_csv_with_lemmatization)\n",
        "display(df1)\n",
        "df2 = pd.read_csv(train_csv_without_lemmatization)\n",
        "display(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>q1_orig</th>\n",
              "      <th>q2_orig</th>\n",
              "      <th>num_word_q1</th>\n",
              "      <th>num_word_q2</th>\n",
              "      <th>num_char_q1</th>\n",
              "      <th>num_common_words</th>\n",
              "      <th>first_word_same</th>\n",
              "      <th>last_word_same</th>\n",
              "      <th>first_2_same</th>\n",
              "      <th>last_2_same</th>\n",
              "      <th>common_word_ratio</th>\n",
              "      <th>num_sent_diff</th>\n",
              "      <th>num_word_diff_ratio</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>num_word_q1_proc</th>\n",
              "      <th>num_word_q2_proc</th>\n",
              "      <th>num_char_q1_proc</th>\n",
              "      <th>num_common_words_proc</th>\n",
              "      <th>first_word_same_proc</th>\n",
              "      <th>last_word_same_proc</th>\n",
              "      <th>first_2_same_proc</th>\n",
              "      <th>last_2_same_proc</th>\n",
              "      <th>common_word_ratio_proc</th>\n",
              "      <th>num_sent_diff_proc</th>\n",
              "      <th>num_word_diff_ratio_proc</th>\n",
              "      <th>lcs_ratio_max</th>\n",
              "      <th>lcs_ratio_min</th>\n",
              "      <th>fuzz_rat</th>\n",
              "      <th>fuzz_part_rat</th>\n",
              "      <th>fuzz_rat_proc</th>\n",
              "      <th>fuzz_part_rat_proc</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>394437</td>\n",
              "      <td>434361</td>\n",
              "      <td>527326</td>\n",
              "      <td>how do i install apk files on my windows phone?</td>\n",
              "      <td>how can i backup a (.xap, / . appx) file insta...</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>install apk file window phone ?</td>\n",
              "      <td>backup ( .xap , / . appx ) file installed wind...</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.267857</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>373988</td>\n",
              "      <td>8023</td>\n",
              "      <td>10567</td>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>major effect cambodia earthquake , effect comp...</td>\n",
              "      <td>major effect cambodia earthquake , effect comp...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183101</td>\n",
              "      <td>280083</td>\n",
              "      <td>280084</td>\n",
              "      <td>how is stack exchange better than quora?</td>\n",
              "      <td>is stack exchange better than quora? why or wh...</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>stack exchange better quora ?</td>\n",
              "      <td>stack exchange better quora ? ?</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43553</td>\n",
              "      <td>78324</td>\n",
              "      <td>78325</td>\n",
              "      <td>how to prevent from pimples to break out insid...</td>\n",
              "      <td>how can i avoid getting pimples inside my nose?</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>prevent pimple break inside nose ?</td>\n",
              "      <td>avoid getting pimple inside nose ?</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>213919</td>\n",
              "      <td>319381</td>\n",
              "      <td>46044</td>\n",
              "      <td>what are some good books and online courses to...</td>\n",
              "      <td>what is a good online course on probability an...</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>good book online course follow grab concept st...</td>\n",
              "      <td>good online course probability statistic ?</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323427</th>\n",
              "      <td>346872</td>\n",
              "      <td>475259</td>\n",
              "      <td>475260</td>\n",
              "      <td>what is the benefit of using const for declari...</td>\n",
              "      <td>what is the benefit of using enum to declare a...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>benefit using const declaring constant ?</td>\n",
              "      <td>benefit using enum declare constant ?</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323428</th>\n",
              "      <td>143678</td>\n",
              "      <td>14804</td>\n",
              "      <td>40458</td>\n",
              "      <td>how can i get a complete list of all old gmail...</td>\n",
              "      <td>how do i find my own gmail accounts list?</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>get complete list old gmail account name ?</td>\n",
              "      <td>find gmail account list ?</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323429</th>\n",
              "      <td>128137</td>\n",
              "      <td>14317</td>\n",
              "      <td>34001</td>\n",
              "      <td>where can i found modern colours and textures ...</td>\n",
              "      <td>where can i get wide range of floor tile, wall...</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>found modern colour texture floor tile sydney ?</td>\n",
              "      <td>get wide range floor tile , wall tile porcelai...</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.229508</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323430</th>\n",
              "      <td>323891</td>\n",
              "      <td>449906</td>\n",
              "      <td>449907</td>\n",
              "      <td>support@ 1877#778#89.69 acer technical support...</td>\n",
              "      <td>@support@ 1877#778#89.69 compaq technical supp...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>support @ 1877 # 778 # 89.69 acer technical su...</td>\n",
              "      <td>@ support @ 1877 # 778 # 89.69 compaq technica...</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471429</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323431</th>\n",
              "      <td>228034</td>\n",
              "      <td>337010</td>\n",
              "      <td>337011</td>\n",
              "      <td>how are lollipops and gummy bears manufactured?</td>\n",
              "      <td>how do lollipops and gummy bears differ?</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>lollipop gummy bear manufactured ?</td>\n",
              "      <td>lollipop gummy bear differ ?</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>323432 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id    qid1    qid2  ... fuzz_rat_proc fuzz_part_rat_proc  Y\n",
              "0       394437  434361  527326  ...          0.53               0.84  0\n",
              "1       373988    8023   10567  ...          0.90               0.89  1\n",
              "2       183101  280083  280084  ...          0.97               1.00  1\n",
              "3        43553   78324   78325  ...          0.68               0.74  1\n",
              "4       213919  319381   46044  ...          0.58               0.60  0\n",
              "...        ...     ...     ...  ...           ...                ... ..\n",
              "323427  346872  475259  475260  ...          0.86               0.81  0\n",
              "323428  143678   14804   40458  ...          0.57               0.72  1\n",
              "323429  128137   14317   34001  ...          0.48               0.43  1\n",
              "323430  323891  449906  449907  ...          0.93               0.92  0\n",
              "323431  228034  337010  337011  ...          0.77               0.75  0\n",
              "\n",
              "[323432 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>q1_orig</th>\n",
              "      <th>q2_orig</th>\n",
              "      <th>num_word_q1</th>\n",
              "      <th>num_word_q2</th>\n",
              "      <th>num_char_q1</th>\n",
              "      <th>num_common_words</th>\n",
              "      <th>first_word_same</th>\n",
              "      <th>last_word_same</th>\n",
              "      <th>first_2_same</th>\n",
              "      <th>last_2_same</th>\n",
              "      <th>common_word_ratio</th>\n",
              "      <th>num_sent_diff</th>\n",
              "      <th>num_word_diff_ratio</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>num_word_q1_proc</th>\n",
              "      <th>num_word_q2_proc</th>\n",
              "      <th>num_char_q1_proc</th>\n",
              "      <th>num_common_words_proc</th>\n",
              "      <th>first_word_same_proc</th>\n",
              "      <th>last_word_same_proc</th>\n",
              "      <th>first_2_same_proc</th>\n",
              "      <th>last_2_same_proc</th>\n",
              "      <th>common_word_ratio_proc</th>\n",
              "      <th>num_sent_diff_proc</th>\n",
              "      <th>num_word_diff_ratio_proc</th>\n",
              "      <th>lcs_ratio_max</th>\n",
              "      <th>lcs_ratio_min</th>\n",
              "      <th>fuzz_rat</th>\n",
              "      <th>fuzz_part_rat</th>\n",
              "      <th>fuzz_rat_proc</th>\n",
              "      <th>fuzz_part_rat_proc</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>394437</td>\n",
              "      <td>434361</td>\n",
              "      <td>527326</td>\n",
              "      <td>how do i install apk files on my windows phone?</td>\n",
              "      <td>how can i backup a (.xap, / . appx) file insta...</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>install apk file window phone ?</td>\n",
              "      <td>backup ( .xap , / . appx ) file installed wind...</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.267857</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>373988</td>\n",
              "      <td>8023</td>\n",
              "      <td>10567</td>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>major effect cambodia earthquake , effect comp...</td>\n",
              "      <td>major effect cambodia earthquake , effect comp...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183101</td>\n",
              "      <td>280083</td>\n",
              "      <td>280084</td>\n",
              "      <td>how is stack exchange better than quora?</td>\n",
              "      <td>is stack exchange better than quora? why or wh...</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>stack exchange better quora ?</td>\n",
              "      <td>stack exchange better quora ? ?</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43553</td>\n",
              "      <td>78324</td>\n",
              "      <td>78325</td>\n",
              "      <td>how to prevent from pimples to break out insid...</td>\n",
              "      <td>how can i avoid getting pimples inside my nose?</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>prevent pimple break inside nose ?</td>\n",
              "      <td>avoid getting pimple inside nose ?</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>213919</td>\n",
              "      <td>319381</td>\n",
              "      <td>46044</td>\n",
              "      <td>what are some good books and online courses to...</td>\n",
              "      <td>what is a good online course on probability an...</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>good book online course follow grab concept st...</td>\n",
              "      <td>good online course probability statistic ?</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323427</th>\n",
              "      <td>346872</td>\n",
              "      <td>475259</td>\n",
              "      <td>475260</td>\n",
              "      <td>what is the benefit of using const for declari...</td>\n",
              "      <td>what is the benefit of using enum to declare a...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>benefit using const declaring constant ?</td>\n",
              "      <td>benefit using enum declare constant ?</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323428</th>\n",
              "      <td>143678</td>\n",
              "      <td>14804</td>\n",
              "      <td>40458</td>\n",
              "      <td>how can i get a complete list of all old gmail...</td>\n",
              "      <td>how do i find my own gmail accounts list?</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>get complete list old gmail account name ?</td>\n",
              "      <td>find gmail account list ?</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323429</th>\n",
              "      <td>128137</td>\n",
              "      <td>14317</td>\n",
              "      <td>34001</td>\n",
              "      <td>where can i found modern colours and textures ...</td>\n",
              "      <td>where can i get wide range of floor tile, wall...</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>found modern colour texture floor tile sydney ?</td>\n",
              "      <td>get wide range floor tile , wall tile porcelai...</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.229508</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323430</th>\n",
              "      <td>323891</td>\n",
              "      <td>449906</td>\n",
              "      <td>449907</td>\n",
              "      <td>support@ 1877#778#89.69 acer technical support...</td>\n",
              "      <td>@support@ 1877#778#89.69 compaq technical supp...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>support @ 1877 # 778 # 89.69 acer technical su...</td>\n",
              "      <td>@ support @ 1877 # 778 # 89.69 compaq technica...</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.471429</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323431</th>\n",
              "      <td>228034</td>\n",
              "      <td>337010</td>\n",
              "      <td>337011</td>\n",
              "      <td>how are lollipops and gummy bears manufactured?</td>\n",
              "      <td>how do lollipops and gummy bears differ?</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>lollipop gummy bear manufactured ?</td>\n",
              "      <td>lollipop gummy bear differ ?</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>323432 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id    qid1    qid2  ... fuzz_rat_proc fuzz_part_rat_proc  Y\n",
              "0       394437  434361  527326  ...          0.53               0.84  0\n",
              "1       373988    8023   10567  ...          0.90               0.89  1\n",
              "2       183101  280083  280084  ...          0.97               1.00  1\n",
              "3        43553   78324   78325  ...          0.68               0.74  1\n",
              "4       213919  319381   46044  ...          0.58               0.60  0\n",
              "...        ...     ...     ...  ...           ...                ... ..\n",
              "323427  346872  475259  475260  ...          0.86               0.81  0\n",
              "323428  143678   14804   40458  ...          0.57               0.72  1\n",
              "323429  128137   14317   34001  ...          0.48               0.43  1\n",
              "323430  323891  449906  449907  ...          0.93               0.92  0\n",
              "323431  228034  337010  337011  ...          0.77               0.75  0\n",
              "\n",
              "[323432 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqXzoTC2_sc"
      },
      "source": [
        "### Define Pipeline and Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTx_VTAh8zfv"
      },
      "source": [
        "def tf_idf_transformer(X):\n",
        "    vectorizer = TfidfVectorizer(analyzer='word')\n",
        "    #tfidf_vectorized = \n",
        "    #print(tfidf_vectorized)\n",
        "    X_tr = vectorizer.fit_transform(X)\n",
        "    return X_tr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGz1xqKH9g2Y"
      },
      "source": [
        "combined_features_lemmatized = df1['question1']+df1['question2']\n",
        "df1 = df1.assign(combined_features=combined_features_lemmatized)\n",
        "combined_features_not_lemmatized = df2['question1']+df2['question2']\n",
        "df2 = df2.assign(combined_features=combined_features_not_lemmatized)\n",
        "df1_tfidf = tf_idf_transformer(df1.combined_features.values.astype(\"U\"))\n",
        "df2_tfidf = tf_idf_transformer(df2.combined_features.values.astype(\"U\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88bWTOgsKRF3"
      },
      "source": [
        "X_train = pd.DataFrame(StandardScaler().fit_transform(X_train), columns=X_train.columns, index=X_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Qu3AUTGWKZTf",
        "outputId": "43b34a04-bc91-4e85-b8a5-a40256f79cfb"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>common_word_ratio</th>\n",
              "      <th>common_word_ratio_proc</th>\n",
              "      <th>first_2_same_proc</th>\n",
              "      <th>fuzz_part_rat</th>\n",
              "      <th>fuzz_part_rat_proc</th>\n",
              "      <th>fuzz_rat</th>\n",
              "      <th>fuzz_rat_proc</th>\n",
              "      <th>last_2_same</th>\n",
              "      <th>last_2_same_proc</th>\n",
              "      <th>last_word_same</th>\n",
              "      <th>last_word_same_proc</th>\n",
              "      <th>lcs_ratio_max</th>\n",
              "      <th>lcs_ratio_max_proc</th>\n",
              "      <th>lcs_ratio_min</th>\n",
              "      <th>lcs_ratio_min_proc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.211293</td>\n",
              "      <td>-0.270399</td>\n",
              "      <td>-0.999132</td>\n",
              "      <td>0.538039</td>\n",
              "      <td>0.616293</td>\n",
              "      <td>0.095089</td>\n",
              "      <td>-0.200991</td>\n",
              "      <td>1.792307</td>\n",
              "      <td>1.559240</td>\n",
              "      <td>1.511933</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>-0.040662</td>\n",
              "      <td>-0.468858</td>\n",
              "      <td>0.247894</td>\n",
              "      <td>-0.274461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.400809</td>\n",
              "      <td>0.248841</td>\n",
              "      <td>1.515165</td>\n",
              "      <td>1.608844</td>\n",
              "      <td>1.036266</td>\n",
              "      <td>1.614730</td>\n",
              "      <td>1.281256</td>\n",
              "      <td>0.533814</td>\n",
              "      <td>0.278353</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>-0.736283</td>\n",
              "      <td>2.221685</td>\n",
              "      <td>1.038586</td>\n",
              "      <td>1.789216</td>\n",
              "      <td>0.655057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.074570</td>\n",
              "      <td>1.739250</td>\n",
              "      <td>1.515165</td>\n",
              "      <td>1.394683</td>\n",
              "      <td>1.456240</td>\n",
              "      <td>0.877934</td>\n",
              "      <td>1.760806</td>\n",
              "      <td>-0.724678</td>\n",
              "      <td>1.559240</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>1.834463</td>\n",
              "      <td>2.326766</td>\n",
              "      <td>2.191386</td>\n",
              "      <td>1.681034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.127851</td>\n",
              "      <td>0.327513</td>\n",
              "      <td>-0.999132</td>\n",
              "      <td>-0.800468</td>\n",
              "      <td>0.149655</td>\n",
              "      <td>-0.227259</td>\n",
              "      <td>0.278560</td>\n",
              "      <td>0.533814</td>\n",
              "      <td>1.559240</td>\n",
              "      <td>1.511933</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>-0.692668</td>\n",
              "      <td>-0.088571</td>\n",
              "      <td>-0.854987</td>\n",
              "      <td>-0.531155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.152902</td>\n",
              "      <td>0.654497</td>\n",
              "      <td>0.258017</td>\n",
              "      <td>-0.800468</td>\n",
              "      <td>-0.410309</td>\n",
              "      <td>-0.411458</td>\n",
              "      <td>-0.157395</td>\n",
              "      <td>-0.724678</td>\n",
              "      <td>0.278353</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>-0.736283</td>\n",
              "      <td>-0.848221</td>\n",
              "      <td>-0.754420</td>\n",
              "      <td>-0.579267</td>\n",
              "      <td>-0.522988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323427</th>\n",
              "      <td>0.564452</td>\n",
              "      <td>0.327513</td>\n",
              "      <td>1.515165</td>\n",
              "      <td>1.073441</td>\n",
              "      <td>0.522965</td>\n",
              "      <td>1.062133</td>\n",
              "      <td>1.106874</td>\n",
              "      <td>-0.724678</td>\n",
              "      <td>0.278353</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>0.885004</td>\n",
              "      <td>-0.113995</td>\n",
              "      <td>0.562312</td>\n",
              "      <td>-0.438150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323428</th>\n",
              "      <td>-0.047690</td>\n",
              "      <td>0.140666</td>\n",
              "      <td>-0.999132</td>\n",
              "      <td>-0.532767</td>\n",
              "      <td>0.242983</td>\n",
              "      <td>-0.227259</td>\n",
              "      <td>-0.244586</td>\n",
              "      <td>-0.724678</td>\n",
              "      <td>0.278353</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>-0.736283</td>\n",
              "      <td>-0.310055</td>\n",
              "      <td>0.008043</td>\n",
              "      <td>-0.001567</td>\n",
              "      <td>0.584905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323429</th>\n",
              "      <td>0.513440</td>\n",
              "      <td>-0.544442</td>\n",
              "      <td>-0.999132</td>\n",
              "      <td>-0.746928</td>\n",
              "      <td>-1.250256</td>\n",
              "      <td>-0.135160</td>\n",
              "      <td>-0.549754</td>\n",
              "      <td>1.792307</td>\n",
              "      <td>1.559240</td>\n",
              "      <td>1.511933</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>-0.458960</td>\n",
              "      <td>-0.656386</td>\n",
              "      <td>-0.654807</td>\n",
              "      <td>-0.829579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323430</th>\n",
              "      <td>1.074570</td>\n",
              "      <td>1.217263</td>\n",
              "      <td>1.515165</td>\n",
              "      <td>1.501764</td>\n",
              "      <td>1.036266</td>\n",
              "      <td>1.568681</td>\n",
              "      <td>1.455637</td>\n",
              "      <td>1.792307</td>\n",
              "      <td>1.559240</td>\n",
              "      <td>1.511933</td>\n",
              "      <td>1.358173</td>\n",
              "      <td>0.962609</td>\n",
              "      <td>0.458906</td>\n",
              "      <td>0.632095</td>\n",
              "      <td>0.064708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323431</th>\n",
              "      <td>1.074570</td>\n",
              "      <td>0.825773</td>\n",
              "      <td>1.515165</td>\n",
              "      <td>0.859280</td>\n",
              "      <td>0.569629</td>\n",
              "      <td>0.877934</td>\n",
              "      <td>0.714514</td>\n",
              "      <td>0.533814</td>\n",
              "      <td>0.278353</td>\n",
              "      <td>-0.661405</td>\n",
              "      <td>-0.736283</td>\n",
              "      <td>1.277224</td>\n",
              "      <td>0.877564</td>\n",
              "      <td>1.223003</td>\n",
              "      <td>0.857719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>323432 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        common_word_ratio  ...  lcs_ratio_min_proc\n",
              "0                0.211293  ...           -0.274461\n",
              "1                1.400809  ...            0.655057\n",
              "2                1.074570  ...            1.681034\n",
              "3               -0.127851  ...           -0.531155\n",
              "4               -0.152902  ...           -0.522988\n",
              "...                   ...  ...                 ...\n",
              "323427           0.564452  ...           -0.438150\n",
              "323428          -0.047690  ...            0.584905\n",
              "323429           0.513440  ...           -0.829579\n",
              "323430           1.074570  ...            0.064708\n",
              "323431           1.074570  ...            0.857719\n",
              "\n",
              "[323432 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH6AhLfnD4TZ",
        "outputId": "a997231d-18f1-43f2-c4b5-b2e11b6d32cd"
      },
      "source": [
        "df1_tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<323432x73209 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2598617 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNFB8SSVFOYU"
      },
      "source": [
        "df1_sm = scipy.sparse.coo_matrix((X_train.values))\n",
        "#df2_sm = scipy.sparse.coo_matrix((df2.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\", \"q1_orig\", \"q2_orig\", \"combined_features\", \"Y\"], axis=1).values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow3hHIgKGsTa"
      },
      "source": [
        "df1_final = scipy.sparse.hstack((df1_sm, df1_tfidf))\n",
        "#df2_final = scipy.sparse.hstack((df2_sm, df2_tfidf))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2o0gtkoBK8L"
      },
      "source": [
        "df1_tf = df1.assign(tfidf=df1_tfidf)\n",
        "df2_tf = df2.assign(tfidf=df2_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EltKe1wTCAdo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "e95ba143-f2d8-4897-94d9-4680501fd4fc"
      },
      "source": [
        "df1_tf_drop = df1_tf.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\", \"q1_orig\", \"q2_orig\", \"combined_features\"], axis=1)\n",
        "df2_tf_drop = df2_tf.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\", \"q1_orig\", \"q2_orig\", \"combined_features\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-943002ff88a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1_tf_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qid1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qid2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q1_orig\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q2_orig\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"combined_features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2_tf_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qid1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"qid2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q1_orig\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q2_orig\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"combined_features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df1_tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfvUR6lrDEPa"
      },
      "source": [
        "x1_train, x1_test, y1_train, y1_test = train_test_split(\n",
        "    df1_final, \n",
        "    df1[\"Y\"],\n",
        "    test_size=0.1, random_state=10)\n",
        "##x2_train, x2_test, y2_train, y2_test = train_test_split(df2_final, \n",
        " #   df2[\"Y\"],test_size=0.1, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "t64kx3_C2_sg",
        "outputId": "14a3bbf2-1c27-4d63-e6c2-15412814a0d8"
      },
      "source": [
        "is_duplicate = ['0', '1']\n",
        "\n",
        "def naiveBayes(x_train,y_train,x_test,y_test, lemmatized_flag, t=1):\n",
        "    nb = Pipeline([('clf', MultinomialNB(alpha=t),)])\n",
        "    nb.fit(x_train,y_train)\n",
        "    if(lemmatized_flag == 0):\n",
        "        pickle.dump(nb,open(model_without_lemmatization_data,'wb'))\n",
        "    else:\n",
        "        pickle.dump(nb,open(model_with_lemmatization_data,'wb'))\n",
        "    y_pred = nb.predict(x_test)\n",
        "    print(\"Naive Bayes: \"+str(accuracy_score(y_pred,y_test)))\n",
        "    print(classification_report(y_test, y_pred,target_names=is_duplicate))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    return nb, accuracy_score(y_pred,y_test)\n",
        "\n",
        "print(\"Dataset with Lemmatization:\")\n",
        "nb_lem = naiveBayes(x1_train,y1_train,x1_test,y1_test, 1, t=0.01)\n",
        "\n",
        "print(\"_________________________________________________________________________\")\n",
        "print(\"Dataset without Lemmatization:\")\n",
        "#nb_wlem = naiveBayes(x2_train,y2_train,x2_test,y2_test, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset with Lemmatization:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c04389bbddc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset with Lemmatization:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnb_lem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_________________________________________________________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-c04389bbddc1>\u001b[0m in \u001b[0;36mnaiveBayes\u001b[0;34m(x_train, y_train, x_test, y_test, lemmatized_flag, t)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatized_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_without_lemmatization_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNtNGIVnz2hk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "028835e4-2333-404e-c501-4a7e15859689"
      },
      "source": [
        "xgb_proba = pd.read_csv(\"/content/drive/MyDrive/Quora-Data/Models/XGRF_probas_train_0.74.csv\", header=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a236c196f1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Quora-Data/Models/XGRF_probas_train_0.74.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Quora-Data/Models/XGRF_probas_train_0.74.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "5m1cjGJ10E-q",
        "outputId": "46ee4989-8bca-4c44-9b4a-6eb147081045"
      },
      "source": [
        "xgb_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fa3b1971e41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'xgb_proba' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYdtHV22_sk"
      },
      "source": [
        "nb_proba = pd.DataFrame(nb_lem[0].predict_proba(df1_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASM9lvz_-YZ1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "uYovx7Ml6H6p",
        "outputId": "401c32aa-0460-4e3b-925a-466542bd633b"
      },
      "source": [
        "df1[[\"q1_orig\", \"q2_orig\"]][nb_proba[1] > 0.8][df1[\"Y\"] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1_orig</th>\n",
              "      <th>q2_orig</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "      <td>what were the major effects of the cambodia ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how is stack exchange better than quora?</td>\n",
              "      <td>is stack exchange better than quora? why or wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>what was the significance of the battle of som...</td>\n",
              "      <td>what was the significance of the battle of som...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>how can you avoid developing limerence?</td>\n",
              "      <td>how do i get over limerence?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>why is marijuana illegal?</td>\n",
              "      <td>why is marijuana still illegal?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323415</th>\n",
              "      <td>what is the shaken baby syndrome?</td>\n",
              "      <td>what is shaken baby syndrome?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323416</th>\n",
              "      <td>what do you think of quanzhou?</td>\n",
              "      <td>what is your review of quanzhou?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323417</th>\n",
              "      <td>how do i lose weight fast?</td>\n",
              "      <td>what is the easiest way to lose weight faster?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323426</th>\n",
              "      <td>what are the major differences between chinese...</td>\n",
              "      <td>what is the difference between chinese and wes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323429</th>\n",
              "      <td>where can i found modern colours and textures ...</td>\n",
              "      <td>where can i get wide range of floor tile, wall...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76997 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  q1_orig                                            q2_orig\n",
              "1       what were the major effects of the cambodia ea...  what were the major effects of the cambodia ea...\n",
              "2                how is stack exchange better than quora?  is stack exchange better than quora? why or wh...\n",
              "8       what was the significance of the battle of som...  what was the significance of the battle of som...\n",
              "14                how can you avoid developing limerence?                       how do i get over limerence?\n",
              "15                              why is marijuana illegal?                    why is marijuana still illegal?\n",
              "...                                                   ...                                                ...\n",
              "323415                  what is the shaken baby syndrome?                      what is shaken baby syndrome?\n",
              "323416                     what do you think of quanzhou?                   what is your review of quanzhou?\n",
              "323417                         how do i lose weight fast?     what is the easiest way to lose weight faster?\n",
              "323426  what are the major differences between chinese...  what is the difference between chinese and wes...\n",
              "323429  where can i found modern colours and textures ...  where can i get wide range of floor tile, wall...\n",
              "\n",
              "[76997 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "J2fsd2lM4nfZ",
        "outputId": "f02c816c-51fe-4c20-b030-130f83f71f88"
      },
      "source": [
        "df1[[\"q1_orig\", \"q2_orig\"]][nb_proba[1] > 0.5][nb_proba[1] < 0.6][df1[\"Y\"] == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1_orig</th>\n",
              "      <th>q2_orig</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>how can i make sure that no one can see my fri...</td>\n",
              "      <td>how do i hide friends list on facebook?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>what is actual meaning of life?</td>\n",
              "      <td>what's the meaning of life? (mathematically an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>is universal health care good? why or why not?</td>\n",
              "      <td>should the u.s. implement a universal health c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>what is the best pen to write the upsc mains e...</td>\n",
              "      <td>which is the best pen to use in upsc exams?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>what are donald trump's chances against hillar...</td>\n",
              "      <td>who will win the election? donald trump or hil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323307</th>\n",
              "      <td>why are so many questions posted to quora that...</td>\n",
              "      <td>why do so many people ask questions on quora t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323325</th>\n",
              "      <td>what languages should be learnt to develop an ...</td>\n",
              "      <td>what computer languages should i learn to be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323329</th>\n",
              "      <td>what is the most probable (the most evidence) ...</td>\n",
              "      <td>what is the most probable base structure of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323376</th>\n",
              "      <td>what's the best solution to the kashmir issue?</td>\n",
              "      <td>what is the solution of kashmir conflict?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323385</th>\n",
              "      <td>what are the best books for cs executive?</td>\n",
              "      <td>where can i find some good books for accountan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4772 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  q1_orig                                            q2_orig\n",
              "80      how can i make sure that no one can see my fri...            how do i hide friends list on facebook?\n",
              "108                       what is actual meaning of life?  what's the meaning of life? (mathematically an...\n",
              "159        is universal health care good? why or why not?  should the u.s. implement a universal health c...\n",
              "364     what is the best pen to write the upsc mains e...        which is the best pen to use in upsc exams?\n",
              "518     what are donald trump's chances against hillar...  who will win the election? donald trump or hil...\n",
              "...                                                   ...                                                ...\n",
              "323307  why are so many questions posted to quora that...  why do so many people ask questions on quora t...\n",
              "323325  what languages should be learnt to develop an ...  what computer languages should i learn to be a...\n",
              "323329  what is the most probable (the most evidence) ...  what is the most probable base structure of th...\n",
              "323376     what's the best solution to the kashmir issue?          what is the solution of kashmir conflict?\n",
              "323385          what are the best books for cs executive?  where can i find some good books for accountan...\n",
              "\n",
              "[4772 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "QoET7PHA54zP",
        "outputId": "0cceb506-a830-4ae1-d32c-51af4e98b027"
      },
      "source": [
        "df1[[\"q1_orig\", \"q2_orig\"]][nb_proba[1] > 0.5][nb_proba[1] < 0.6][df1[\"Y\"] != 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1_orig</th>\n",
              "      <th>q2_orig</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>what can you say about filipino people?</td>\n",
              "      <td>what do you not know about filipinos?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>what are the advantages and disadvantages of v...</td>\n",
              "      <td>what are the advantages and disadvantages of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>what if a google search was case-sensitive?</td>\n",
              "      <td>is google search case sensitive?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>why is there no option to +1 quora posts?</td>\n",
              "      <td>why does quora have an option of answering one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>what universities does federal signal recruit ...</td>\n",
              "      <td>what universities does third federal savings r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323015</th>\n",
              "      <td>what if china attacked the usa?</td>\n",
              "      <td>what will happen if the usa attacks china?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323111</th>\n",
              "      <td>what do people misunderstand about space travel?</td>\n",
              "      <td>what does science say about space travel?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323123</th>\n",
              "      <td>which usa visa should i apply for?</td>\n",
              "      <td>where should i apply for usa visa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323338</th>\n",
              "      <td>why did war between india and pakistan happene...</td>\n",
              "      <td>what will happen if there is a war between ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323374</th>\n",
              "      <td>what is the easiest, painless way to die insta...</td>\n",
              "      <td>which is the most awesome way to die?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5478 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  q1_orig                                            q2_orig\n",
              "111               what can you say about filipino people?              what do you not know about filipinos?\n",
              "139     what are the advantages and disadvantages of v...  what are the advantages and disadvantages of t...\n",
              "193           what if a google search was case-sensitive?                   is google search case sensitive?\n",
              "225             why is there no option to +1 quora posts?  why does quora have an option of answering one...\n",
              "228     what universities does federal signal recruit ...  what universities does third federal savings r...\n",
              "...                                                   ...                                                ...\n",
              "323015                    what if china attacked the usa?         what will happen if the usa attacks china?\n",
              "323111   what do people misunderstand about space travel?          what does science say about space travel?\n",
              "323123                 which usa visa should i apply for?                 where should i apply for usa visa?\n",
              "323338  why did war between india and pakistan happene...  what will happen if there is a war between ind...\n",
              "323374  what is the easiest, painless way to die insta...              which is the most awesome way to die?\n",
              "\n",
              "[5478 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zQQ6WyI5Gx_",
        "outputId": "b93ab7a3-9c22-4370-eae5-d6b2ebe36d1f"
      },
      "source": [
        "df1[\"Y\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         1\n",
              "2         1\n",
              "3         1\n",
              "4         0\n",
              "         ..\n",
              "323427    0\n",
              "323428    1\n",
              "323429    1\n",
              "323430    0\n",
              "323431    0\n",
              "Name: Y, Length: 323432, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFTLl4Mih1-C",
        "outputId": "c06e2368-c6a1-42a8-d836-bcbce43db976"
      },
      "source": [
        "for alpha in [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10]:\n",
        "    print(alpha)\n",
        "    nb_lem = naiveBayes(x1_train,y1_train,x1_test,y1_test, 1, t=alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001\n",
            "Naive Bayes: 0.7383749690823646\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.73      0.78     20341\n",
            "           1       0.62      0.76      0.68     12003\n",
            "\n",
            "    accuracy                           0.74     32344\n",
            "   macro avg       0.73      0.74      0.73     32344\n",
            "weighted avg       0.76      0.74      0.74     32344\n",
            "\n",
            "[[14776  5565]\n",
            " [ 2897  9106]]\n",
            "0.001\n",
            "Naive Bayes: 0.7366126638634677\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.72      0.77     20341\n",
            "           1       0.62      0.76      0.68     12003\n",
            "\n",
            "    accuracy                           0.74     32344\n",
            "   macro avg       0.73      0.74      0.73     32344\n",
            "weighted avg       0.76      0.74      0.74     32344\n",
            "\n",
            "[[14660  5681]\n",
            " [ 2838  9165]]\n",
            "0.005\n",
            "Naive Bayes: 0.7339846648528321\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.71      0.77     20341\n",
            "           1       0.61      0.77      0.68     12003\n",
            "\n",
            "    accuracy                           0.73     32344\n",
            "   macro avg       0.73      0.74      0.73     32344\n",
            "weighted avg       0.76      0.73      0.74     32344\n",
            "\n",
            "[[14511  5830]\n",
            " [ 2774  9229]]\n",
            "0.01\n",
            "Naive Bayes: 0.7320368538214197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.71      0.77     20341\n",
            "           1       0.61      0.77      0.68     12003\n",
            "\n",
            "    accuracy                           0.73     32344\n",
            "   macro avg       0.72      0.74      0.73     32344\n",
            "weighted avg       0.75      0.73      0.74     32344\n",
            "\n",
            "[[14422  5919]\n",
            " [ 2748  9255]]\n",
            "0.05\n",
            "Naive Bayes: 0.7278320554044027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.70      0.76     20341\n",
            "           1       0.60      0.78      0.68     12003\n",
            "\n",
            "    accuracy                           0.73     32344\n",
            "   macro avg       0.72      0.74      0.72     32344\n",
            "weighted avg       0.75      0.73      0.73     32344\n",
            "\n",
            "[[14229  6112]\n",
            " [ 2691  9312]]\n",
            "0.1\n",
            "Naive Bayes: 0.7252658916646055\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.70      0.76     20341\n",
            "           1       0.60      0.78      0.68     12003\n",
            "\n",
            "    accuracy                           0.73     32344\n",
            "   macro avg       0.72      0.74      0.72     32344\n",
            "weighted avg       0.75      0.73      0.73     32344\n",
            "\n",
            "[[14137  6204]\n",
            " [ 2682  9321]]\n",
            "1\n",
            "Naive Bayes: 0.7149394014345782\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.69      0.75     20341\n",
            "           1       0.59      0.76      0.66     12003\n",
            "\n",
            "    accuracy                           0.71     32344\n",
            "   macro avg       0.71      0.72      0.71     32344\n",
            "weighted avg       0.74      0.71      0.72     32344\n",
            "\n",
            "[[14013  6328]\n",
            " [ 2892  9111]]\n",
            "10\n",
            "Naive Bayes: 0.6963888201830324\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.77     20341\n",
            "           1       0.62      0.47      0.53     12003\n",
            "\n",
            "    accuracy                           0.70     32344\n",
            "   macro avg       0.67      0.65      0.65     32344\n",
            "weighted avg       0.69      0.70      0.69     32344\n",
            "\n",
            "[[16883  3458]\n",
            " [ 6362  5641]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}