{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "571ec981051b4f19829a6b7379dbcd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62bb8097743248c9b0e1e89389da4de7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26786d86874b4b60b9f982e2c2714d0e",
              "IPY_MODEL_f91e1526ed5d47bd9aa449d62a3fd217"
            ]
          }
        },
        "62bb8097743248c9b0e1e89389da4de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26786d86874b4b60b9f982e2c2714d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3493398d1b0e458c8d8d7117fd519e73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_550e14391bfc47ba948de49b7ecb7f04"
          }
        },
        "f91e1526ed5d47bd9aa449d62a3fd217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8dcf6f317884cffb970dede6f31deac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1999995/? [03:04&lt;00:00, 10847.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2069f3366aa4d9d8dac41ae8cfa9431"
          }
        },
        "3493398d1b0e458c8d8d7117fd519e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "550e14391bfc47ba948de49b7ecb7f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8dcf6f317884cffb970dede6f31deac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2069f3366aa4d9d8dac41ae8cfa9431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBsKXpp0sXzx"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "import keras\n",
        "from keras.preprocessing.text import one_hot,Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Flatten ,Embedding,Input\n",
        "from keras.models import Model\n",
        "import re\n",
        "import gensim.downloader\n",
        "import multiprocessing\n",
        "import pickle\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ5uQKXeq3D9",
        "outputId": "f0736f88-0ca9-4ef4-ccfa-8b22c1f79f59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhoueVIir_eF",
        "outputId": "b93c9195-9ca2-4852-868a-a81a1268d5c5"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/Quora-Data/\"\n",
        "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n",
        "FILE = data_dir + \"fastText.vec\"\n",
        "\n",
        "if os.path.isdir(FILE):\n",
        "    print(\"fastText exists.\")\n",
        "else:\n",
        "    !wget -P $FILE $URL\n",
        "    !unzip $FILE/crawl-300d-2M.vec.zip -d $FILE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastText exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDzFLW3CstJb"
      },
      "source": [
        "X_train = pd.read_csv(data_dir + \"pre-processing/preprocessing_text_train.csv\").fillna('')\n",
        "X_test = pd.read_csv(data_dir + \"pre-processing/preprocessing_text_test.csv\").fillna('')\n",
        "Y_train = pd.read_csv(data_dir + \"pre-processing/train.csv\")[\"Y\"]\n",
        "Y_test = pd.read_csv(data_dir + \"pre-processing/test.csv\")[\"Y\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdEri0egtyUQ"
      },
      "source": [
        "def text_to_wordlist(text, pool=\"max\", remove_stopwords=False, stem_words=False):\n",
        "    global word_idx, idx, max_len, counter\n",
        "    counter += 1\n",
        "    if counter%50000 == 0:\n",
        "        print(counter/323344)\n",
        "    # Clean the text, with the option to remove stopwords and to stem words.\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    \n",
        "    # Optionally, shorten words to their stems\n",
        "    if stem_words:\n",
        "        text = text.split()\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        stemmed_words = [stemmer.stem(word) for word in text]\n",
        "        text = \" \".join(stemmed_words)\n",
        "\n",
        "    words = text.split()\n",
        "    for token in words:\n",
        "        if token not in word2idx:\n",
        "            word2idx[token] = idx\n",
        "            idx += 1\n",
        "    max_len = max(max_len, len(words))\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uka1yFCHyohp",
        "outputId": "23e6fcae-666b-40af-8136-24cce8346070"
      },
      "source": [
        "word2idx = dict()\n",
        "word2idx['<pad>'] = 0\n",
        "word2idx['<unk>'] = 1\n",
        "idx = 2\n",
        "max_len = 0\n",
        "counter = 0\n",
        "q1_df_train = pd.DataFrame(map(text_to_wordlist, X_train[\"question1\"]))\n",
        "counter = 0\n",
        "q2_df_train = pd.DataFrame(map(text_to_wordlist, X_train[\"question2\"]))\n",
        "counter = 0\n",
        "q1_df_test = pd.DataFrame(map(text_to_wordlist, X_test[\"question1\"]))\n",
        "counter = 0\n",
        "q2_df_test = pd.DataFrame(map(text_to_wordlist, X_test[\"question2\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15463407392745807\n",
            "0.30926814785491613\n",
            "0.46390222178237417\n",
            "0.6185362957098323\n",
            "0.7731703696372904\n",
            "0.9278044435647483\n",
            "0.15463407392745807\n",
            "0.30926814785491613\n",
            "0.46390222178237417\n",
            "0.6185362957098323\n",
            "0.7731703696372904\n",
            "0.9278044435647483\n",
            "0.15463407392745807\n",
            "0.15463407392745807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oO6YGrfzezH",
        "outputId": "3f1161a5-a34f-4312-d0ef-eb6f3976c584"
      },
      "source": [
        "max_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "3LZE5WRf0BAr",
        "outputId": "7ecf7e13-86ff-4c8b-d6a9-8a81b1113576"
      },
      "source": [
        "q1_df_train[0].apply(lambda x: len(x.split(' '))).value_counts().sort_index().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6063581450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "571ec981051b4f19829a6b7379dbcd61",
            "62bb8097743248c9b0e1e89389da4de7",
            "26786d86874b4b60b9f982e2c2714d0e",
            "f91e1526ed5d47bd9aa449d62a3fd217",
            "3493398d1b0e458c8d8d7117fd519e73",
            "550e14391bfc47ba948de49b7ecb7f04",
            "b8dcf6f317884cffb970dede6f31deac",
            "a2069f3366aa4d9d8dac41ae8cfa9431"
          ]
        },
        "id": "bpyFkzj08Bt7",
        "outputId": "76ae9f3d-64d5-4a18-f1bd-d4ef5800ead8"
      },
      "source": [
        "fname = data_dir + \"fastText.vec/crawl-300d-2M.vec\"\n",
        "fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "n, d = map(int, fin.readline().split())\n",
        "\n",
        "# Initilize random embeddings\n",
        "embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n",
        "embeddings[word2idx['<pad>']] = np.zeros((d,))\n",
        "\n",
        "# Load pretrained vectors\n",
        "count = 0\n",
        "for line in tqdm_notebook(fin):\n",
        "    tokens = line.rstrip().split(' ')\n",
        "    word = tokens[0]\n",
        "    if word in word2idx:\n",
        "        count += 1\n",
        "        embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)\n",
        "\n",
        "print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "571ec981051b4f19829a6b7379dbcd61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "There are 58952 / 78053 pretrained vectors found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWYBRiGiA6DB"
      },
      "source": [
        "embeddings = torch.tensor(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwgfWAtm_RXk"
      },
      "source": [
        "def encode(texts, word2idx, max_len):\n",
        "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
        "    their index in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
        "            shape (N, max_len). It will the input of our CNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = []\n",
        "    for sent in texts:\n",
        "        tokenized_sent = sent.split()[:max_len]\n",
        "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
        "        input_ids.append(input_id)\n",
        "    \n",
        "    return np.array(input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNBNxenAFDA"
      },
      "source": [
        "q1_train_inp_ids = encode(q1_df_train[0].to_list(), word2idx, 14)\n",
        "q2_train_inp_ids = encode(q2_df_train[0].to_list(), word2idx, 14)\n",
        "q1_test_inp_ids = encode(q1_df_test[0].to_list(), word2idx, 14)\n",
        "q2_test_inp_ids = encode(q2_df_test[0].to_list(), word2idx, 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5ZDC7dcMov1"
      },
      "source": [
        "train_inp_ids = np.stack([q1_train_inp_ids, q2_train_inp_ids], axis=-1)\n",
        "test_inp_ids = np.stack([q1_test_inp_ids, q2_test_inp_ids], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUgzYxM9X4nK"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(train_inp_ids, Y_train, test_size=0.2)\n",
        "X_test = test_inp_ids\n",
        "X_train_t = torch.from_numpy(X_train)\n",
        "X_test_t = torch.from_numpy(X_test)\n",
        "X_val_t = torch.from_numpy(X_val)\n",
        "Y_train_t = torch.from_numpy(Y_train.values.astype(\"float32\"))\n",
        "Y_test_t = torch.from_numpy(Y_test.values.astype(\"float32\"))\n",
        "Y_val_t = torch.from_numpy(Y_val.values.astype(\"float32\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQC6tq1Li_ya",
        "outputId": "138ca5b8-1ddc-4e3a-958a-32e61b237672"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRPPKjrjjAor"
      },
      "source": [
        "loss_list_train = []\n",
        "loss_list_val = []\n",
        "accuracy_list_train = []\n",
        "accuracy_list_val = []\n",
        "iteration_list_val = []\n",
        "iteration_list_train = []\n",
        "loss_train_epoch = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0o1QQsbHmet",
        "outputId": "88209847-7e9c-410e-f32d-c6f042698058"
      },
      "source": [
        "batch_size = 100\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X #torch.tensor(X, dtype=torch.float32) #X\n",
        "        self.Y = torch.tensor(Y, dtype=torch.float32) # Y.detach().clone() #torch.from_numpy(np.asarray(Y).astype('long'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.Y[index]\n",
        "        image = self.X[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "SBIcsVfQB6rd",
        "outputId": "e3324e41-0e56-495b-c951-d5b526339433"
      },
      "source": [
        "class MyCNN(nn.Module):\n",
        "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
        "    def __init__(self, pretrained_embedding=None, embed_dim=300, filter_sizes=[2, 3, 4, 5], num_filters=[100, 100, 100, 100], num_classes=1, dropout=0.3):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embedding, freeze=True)\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim*2, out_channels=num_filters[i], kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
        "        # self.fc1 = nn.Linear(np.sum(num_filters), 256)\n",
        "        # self.fc2 = nn.Linear(256, 128)\n",
        "        # self.fc3 = nn.Linear(128, 32)\n",
        "        # self.fc4 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
        "        x_embed = self.embedding(input_ids).view(-1, 14, 600).float() # reshape(-1, 15, 600).float()\n",
        "\n",
        "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
        "        # Output shape: (b, embed_dim, max_len)\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "\n",
        "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "        \n",
        "        # Concatenate x_pool_list to feed the fully connected layer.\n",
        "        # Output shape: (b, sum(num_filters))\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "        \n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = MyCNN(pretrained_embedding=embeddings)\n",
        "\n",
        "model.to(device)\n",
        "num_epochs = 1000\n",
        "count = 0\n",
        "\n",
        "error = nn.BCEWithLogitsLoss() #nn.CrossEntropyLoss()\n",
        "\n",
        "# After running several times, this was found to be the best\n",
        "learning_rate = 0.01\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "# learning_rate = 0.01\n",
        "# # https://pytorch.org/docs/stable/optim.html\n",
        "# optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.008)\n",
        "optimizer = torch.optim.ASGD(model.parameters(), lr=learning_rate, weight_decay=0.008)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%100 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100, Val Loss: 420.313, Val Accuracy: 0.631 Train Loss: 1682.999, Train Accuracy: 0.630\n",
            "Iteration: 200, Val Loss: 418.009, Val Accuracy: 0.631 Train Loss: 1673.973, Train Accuracy: 0.630\n",
            "Iteration: 300, Val Loss: 416.323, Val Accuracy: 0.631 Train Loss: 1667.040, Train Accuracy: 0.630\n",
            "Iteration: 400, Val Loss: 414.710, Val Accuracy: 0.631 Train Loss: 1660.727, Train Accuracy: 0.630\n",
            "Iteration: 500, Val Loss: 413.052, Val Accuracy: 0.631 Train Loss: 1653.815, Train Accuracy: 0.630\n",
            "Iteration: 600, Val Loss: 411.352, Val Accuracy: 0.631 Train Loss: 1647.049, Train Accuracy: 0.630\n",
            "Iteration: 700, Val Loss: 409.680, Val Accuracy: 0.632 Train Loss: 1640.202, Train Accuracy: 0.630\n",
            "Iteration: 800, Val Loss: 408.059, Val Accuracy: 0.632 Train Loss: 1633.699, Train Accuracy: 0.631\n",
            "Iteration: 900, Val Loss: 406.546, Val Accuracy: 0.633 Train Loss: 1627.435, Train Accuracy: 0.631\n",
            "Iteration: 1000, Val Loss: 404.829, Val Accuracy: 0.633 Train Loss: 1620.523, Train Accuracy: 0.632\n",
            "Iteration: 1100, Val Loss: 403.252, Val Accuracy: 0.638 Train Loss: 1613.904, Train Accuracy: 0.636\n",
            "Iteration: 1200, Val Loss: 401.678, Val Accuracy: 0.638 Train Loss: 1607.562, Train Accuracy: 0.637\n",
            "Iteration: 1300, Val Loss: 400.076, Val Accuracy: 0.642 Train Loss: 1600.989, Train Accuracy: 0.641\n",
            "Iteration: 1400, Val Loss: 398.504, Val Accuracy: 0.645 Train Loss: 1594.500, Train Accuracy: 0.645\n",
            "Iteration: 1500, Val Loss: 397.060, Val Accuracy: 0.656 Train Loss: 1588.408, Train Accuracy: 0.656\n",
            "Iteration: 1600, Val Loss: 395.461, Val Accuracy: 0.653 Train Loss: 1582.084, Train Accuracy: 0.653\n",
            "Iteration: 1700, Val Loss: 393.973, Val Accuracy: 0.661 Train Loss: 1575.851, Train Accuracy: 0.660\n",
            "Iteration: 1800, Val Loss: 392.441, Val Accuracy: 0.666 Train Loss: 1569.565, Train Accuracy: 0.666\n",
            "Iteration: 1900, Val Loss: 390.948, Val Accuracy: 0.670 Train Loss: 1563.447, Train Accuracy: 0.670\n",
            "Iteration: 2000, Val Loss: 389.536, Val Accuracy: 0.677 Train Loss: 1557.558, Train Accuracy: 0.677\n",
            "Iteration: 2100, Val Loss: 388.347, Val Accuracy: 0.682 Train Loss: 1552.571, Train Accuracy: 0.682\n",
            "Iteration: 2200, Val Loss: 387.034, Val Accuracy: 0.683 Train Loss: 1547.130, Train Accuracy: 0.683\n",
            "Iteration: 2300, Val Loss: 385.732, Val Accuracy: 0.686"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4866067a2d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "dDaXreJtW0oC",
        "outputId": "7918734b-e02c-45bf-d153-a35a8f02b8d1"
      },
      "source": [
        "learning_rate = 0.1\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%100 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 2400, Val Loss: 377.932, Val Accuracy: 0.701 Train Loss: 1508.921, Train Accuracy: 0.703\n",
            "Iteration: 2500, Val Loss: 372.137, Val Accuracy: 0.703 Train Loss: 1484.234, Train Accuracy: 0.704\n",
            "Iteration: 2600, Val Loss: 367.700, Val Accuracy: 0.709 Train Loss: 1464.847, Train Accuracy: 0.710\n",
            "Iteration: 2700, Val Loss: 364.591, Val Accuracy: 0.717 Train Loss: 1451.376, Train Accuracy: 0.720\n",
            "Iteration: 2800, Val Loss: 360.630, Val Accuracy: 0.720 Train Loss: 1434.105, Train Accuracy: 0.723\n",
            "Iteration: 2900, Val Loss: 358.191, Val Accuracy: 0.721 Train Loss: 1422.572, Train Accuracy: 0.724\n",
            "Iteration: 3000, Val Loss: 357.183, Val Accuracy: 0.725 Train Loss: 1418.050, Train Accuracy: 0.729\n",
            "Iteration: 3100, Val Loss: 354.348, Val Accuracy: 0.724 Train Loss: 1405.693, Train Accuracy: 0.728\n",
            "Iteration: 3200, Val Loss: 357.003, Val Accuracy: 0.726 Train Loss: 1415.544, Train Accuracy: 0.731\n",
            "Iteration: 3300, Val Loss: 350.430, Val Accuracy: 0.727 Train Loss: 1386.184, Train Accuracy: 0.732\n",
            "Iteration: 3400, Val Loss: 349.019, Val Accuracy: 0.731 Train Loss: 1379.890, Train Accuracy: 0.736\n",
            "Iteration: 3500, Val Loss: 347.908, Val Accuracy: 0.731 Train Loss: 1373.589, Train Accuracy: 0.737\n",
            "Iteration: 3600, Val Loss: 346.446, Val Accuracy: 0.732 Train Loss: 1366.517, Train Accuracy: 0.738\n",
            "Iteration: 3700, Val Loss: 346.684, Val Accuracy: 0.728 Train Loss: 1364.576, Train Accuracy: 0.735\n",
            "Iteration: 3800, Val Loss: 349.799, Val Accuracy: 0.732 Train Loss: 1377.261, Train Accuracy: 0.739\n",
            "Iteration: 3900, Val Loss: 343.589, Val Accuracy: 0.735 Train Loss: 1351.965, Train Accuracy: 0.742\n",
            "Iteration: 4000, Val Loss: 343.060, Val Accuracy: 0.733 Train Loss: 1348.108, Train Accuracy: 0.740\n",
            "Iteration: 4100, Val Loss: 341.768, Val Accuracy: 0.736 Train Loss: 1341.754, Train Accuracy: 0.742\n",
            "Iteration: 4200, Val Loss: 340.825, Val Accuracy: 0.737 Train Loss: 1337.964, Train Accuracy: 0.746\n",
            "Iteration: 4300, Val Loss: 341.135, Val Accuracy: 0.734 Train Loss: 1337.725, Train Accuracy: 0.742\n",
            "Iteration: 4400, Val Loss: 342.125, Val Accuracy: 0.738"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2258d86b38c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.max(outputs, 1)[1].to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2827\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GidMcGiCtMsE",
        "outputId": "1ae07cb6-6238-4dfb-85c9-11a229174d02"
      },
      "source": [
        "learning_rate = 0.05\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%100 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 4500, Val Loss: 339.235, Val Accuracy: 0.740 Train Loss: 1328.721, Train Accuracy: 0.748\n",
            "Iteration: 4600, Val Loss: 338.296, Val Accuracy: 0.738 Train Loss: 1323.685, Train Accuracy: 0.746\n",
            "Iteration: 4700, Val Loss: 337.829, Val Accuracy: 0.740 Train Loss: 1320.652, Train Accuracy: 0.749\n",
            "Iteration: 4800, Val Loss: 337.187, Val Accuracy: 0.742 Train Loss: 1318.138, Train Accuracy: 0.752\n",
            "Iteration: 4900, Val Loss: 336.503, Val Accuracy: 0.742 Train Loss: 1314.274, Train Accuracy: 0.752\n",
            "Iteration: 5000, Val Loss: 336.444, Val Accuracy: 0.742 Train Loss: 1313.123, Train Accuracy: 0.750\n",
            "Iteration: 5100, Val Loss: 336.820, Val Accuracy: 0.743 Train Loss: 1315.024, Train Accuracy: 0.753\n",
            "Iteration: 5200, Val Loss: 335.469, Val Accuracy: 0.743 Train Loss: 1308.871, Train Accuracy: 0.752\n",
            "Iteration: 5300, Val Loss: 337.103, Val Accuracy: 0.744 Train Loss: 1315.297, Train Accuracy: 0.755\n",
            "Iteration: 5400, Val Loss: 334.724, Val Accuracy: 0.743 Train Loss: 1303.589, Train Accuracy: 0.753\n",
            "Iteration: 5500, Val Loss: 334.418, Val Accuracy: 0.745 Train Loss: 1302.337, Train Accuracy: 0.756\n",
            "Iteration: 5600, Val Loss: 334.161, Val Accuracy: 0.744 Train Loss: 1300.188, Train Accuracy: 0.756\n",
            "Iteration: 5700, Val Loss: 333.965, Val Accuracy: 0.746 Train Loss: 1298.728, Train Accuracy: 0.757\n",
            "Iteration: 5800, Val Loss: 334.199, Val Accuracy: 0.743 Train Loss: 1297.527, Train Accuracy: 0.753\n",
            "Iteration: 5900, Val Loss: 336.137, Val Accuracy: 0.745 Train Loss: 1305.551, Train Accuracy: 0.757\n",
            "Iteration: 6000, Val Loss: 333.192, Val Accuracy: 0.745 Train Loss: 1293.732, Train Accuracy: 0.756\n",
            "Iteration: 6100, Val Loss: 333.130, Val Accuracy: 0.743 Train Loss: 1292.291, Train Accuracy: 0.755\n",
            "Iteration: 6200, Val Loss: 332.928, Val Accuracy: 0.743 Train Loss: 1290.588, Train Accuracy: 0.755\n",
            "Iteration: 6300, Val Loss: 332.061, Val Accuracy: 0.746 Train Loss: 1287.180, Train Accuracy: 0.758\n",
            "Iteration: 6400, Val Loss: 332.513, Val Accuracy: 0.744 Train Loss: 1288.210, Train Accuracy: 0.756\n",
            "Iteration: 6500, Val Loss: 333.621, Val Accuracy: 0.747 Train Loss: 1292.817, Train Accuracy: 0.760\n",
            "Iteration: 6600, Val Loss: 333.536, Val Accuracy: 0.747 Train Loss: 1291.607, Train Accuracy: 0.761\n",
            "Iteration: 6700, Val Loss: 331.541, Val Accuracy: 0.745 Train Loss: 1283.244, Train Accuracy: 0.758\n",
            "Iteration: 6800, Val Loss: 332.910, Val Accuracy: 0.742 Train Loss: 1289.371, Train Accuracy: 0.754\n",
            "Iteration: 6900, Val Loss: 330.820, Val Accuracy: 0.746 Train Loss: 1278.850, Train Accuracy: 0.759\n",
            "Iteration: 7000, Val Loss: 330.885, Val Accuracy: 0.747 Train Loss: 1279.427, Train Accuracy: 0.758\n",
            "Iteration: 7100, Val Loss: 330.027, Val Accuracy: 0.748 Train Loss: 1275.291, Train Accuracy: 0.761\n",
            "Iteration: 7200, Val Loss: 330.233, Val Accuracy: 0.749 Train Loss: 1275.610, Train Accuracy: 0.762\n",
            "Iteration: 7300, Val Loss: 331.034, Val Accuracy: 0.750 Train Loss: 1279.167, Train Accuracy: 0.765\n",
            "Iteration: 7400, Val Loss: 330.831, Val Accuracy: 0.745 Train Loss: 1277.331, Train Accuracy: 0.757\n",
            "Iteration: 7500, Val Loss: 328.958, Val Accuracy: 0.749 Train Loss: 1269.453, Train Accuracy: 0.763\n",
            "Iteration: 7600, Val Loss: 329.650, Val Accuracy: 0.750 Train Loss: 1271.955, Train Accuracy: 0.764\n",
            "Iteration: 7700, Val Loss: 328.871, Val Accuracy: 0.750 Train Loss: 1268.180, Train Accuracy: 0.765\n",
            "Iteration: 7800, Val Loss: 328.514, Val Accuracy: 0.751 Train Loss: 1266.427, Train Accuracy: 0.764\n",
            "Iteration: 7900, Val Loss: 329.637, Val Accuracy: 0.752 Train Loss: 1271.288, Train Accuracy: 0.767\n",
            "Iteration: 8000, Val Loss: 328.271, Val Accuracy: 0.749 Train Loss: 1263.672, Train Accuracy: 0.762\n",
            "Iteration: 8100, Val Loss: 329.876, Val Accuracy: 0.753 Train Loss: 1271.037, Train Accuracy: 0.768\n",
            "Iteration: 8200, Val Loss: 327.932, Val Accuracy: 0.750 Train Loss: 1261.790, Train Accuracy: 0.765\n",
            "Iteration: 8300, Val Loss: 331.720, Val Accuracy: 0.742 Train Loss: 1275.190, Train Accuracy: 0.754\n",
            "Iteration: 8400, Val Loss: 327.686, Val Accuracy: 0.749 Train Loss: 1257.740, Train Accuracy: 0.764\n",
            "Iteration: 8500, Val Loss: 327.254, Val Accuracy: 0.750 Train Loss: 1256.383, Train Accuracy: 0.766\n",
            "Iteration: 8600, Val Loss: 327.895, Val Accuracy: 0.749 Train Loss: 1259.600, Train Accuracy: 0.763\n",
            "Iteration: 8700, Val Loss: 327.017, Val Accuracy: 0.751 Train Loss: 1254.467, Train Accuracy: 0.766\n",
            "Iteration: 8800, Val Loss: 327.998, Val Accuracy: 0.753 Train Loss: 1258.547, Train Accuracy: 0.770\n",
            "Iteration: 8900, Val Loss: 327.252, Val Accuracy: 0.752 Train Loss: 1255.528, Train Accuracy: 0.769\n",
            "Iteration: 9000, Val Loss: 327.835, Val Accuracy: 0.747 Train Loss: 1256.412, Train Accuracy: 0.761\n",
            "Iteration: 9100, Val Loss: 326.742, Val Accuracy: 0.750 Train Loss: 1251.734, Train Accuracy: 0.765\n",
            "Iteration: 9200, Val Loss: 326.015, Val Accuracy: 0.753 Train Loss: 1249.180, Train Accuracy: 0.767\n",
            "Iteration: 9300, Val Loss: 326.096, Val Accuracy: 0.753 Train Loss: 1249.438, Train Accuracy: 0.771\n",
            "Iteration: 9400, Val Loss: 326.336, Val Accuracy: 0.756 Train Loss: 1251.421, Train Accuracy: 0.772\n",
            "Iteration: 9500, Val Loss: 327.035, Val Accuracy: 0.750 Train Loss: 1251.338, Train Accuracy: 0.764\n",
            "Iteration: 9600, Val Loss: 325.256, Val Accuracy: 0.754 Train Loss: 1244.354, Train Accuracy: 0.770\n",
            "Iteration: 9700, Val Loss: 326.807, Val Accuracy: 0.749 Train Loss: 1249.677, Train Accuracy: 0.763\n",
            "Iteration: 9800, Val Loss: 325.112, Val Accuracy: 0.754 Train Loss: 1242.865, Train Accuracy: 0.770\n",
            "Iteration: 9900, Val Loss: 324.655, Val Accuracy: 0.755 Train Loss: 1241.888, Train Accuracy: 0.772\n",
            "Iteration: 10000, Val Loss: 327.431, Val Accuracy: 0.754 Train Loss: 1253.220, Train Accuracy: 0.774\n",
            "Iteration: 10100, Val Loss: 324.029, Val Accuracy: 0.754 Train Loss: 1238.326, Train Accuracy: 0.771\n",
            "Iteration: 10200, Val Loss: 324.955, Val Accuracy: 0.753 Train Loss: 1241.462, Train Accuracy: 0.772\n",
            "Iteration: 10300, Val Loss: 325.322, Val Accuracy: 0.751 Train Loss: 1242.111, Train Accuracy: 0.766\n",
            "Iteration: 10400, Val Loss: 323.912, Val Accuracy: 0.756 Train Loss: 1236.021, Train Accuracy: 0.772\n",
            "Iteration: 10500, Val Loss: 324.389, Val Accuracy: 0.757 Train Loss: 1238.871, Train Accuracy: 0.775\n",
            "Iteration: 10600, Val Loss: 325.979, Val Accuracy: 0.756 Train Loss: 1244.023, Train Accuracy: 0.776\n",
            "Iteration: 10700, Val Loss: 323.821, Val Accuracy: 0.756 Train Loss: 1235.374, Train Accuracy: 0.775\n",
            "Iteration: 10800, Val Loss: 323.926, Val Accuracy: 0.753 Train Loss: 1234.289, Train Accuracy: 0.770\n",
            "Iteration: 10900, Val Loss: 324.915, Val Accuracy: 0.757 Train Loss: 1237.490, Train Accuracy: 0.775\n",
            "Iteration: 11000, Val Loss: 324.223, Val Accuracy: 0.757 Train Loss: 1233.462, Train Accuracy: 0.776\n",
            "Iteration: 11100, Val Loss: 325.978, Val Accuracy: 0.755 Train Loss: 1241.451, Train Accuracy: 0.776\n",
            "Iteration: 11200, Val Loss: 322.493, Val Accuracy: 0.757 Train Loss: 1227.166, Train Accuracy: 0.774\n",
            "Iteration: 11300, Val Loss: 327.562, Val Accuracy: 0.754 Train Loss: 1246.833, Train Accuracy: 0.776\n",
            "Iteration: 11400, Val Loss: 322.802, Val Accuracy: 0.756 Train Loss: 1226.220, Train Accuracy: 0.775\n",
            "Iteration: 11500, Val Loss: 323.460, Val Accuracy: 0.752 Train Loss: 1228.797, Train Accuracy: 0.770\n",
            "Iteration: 11600, Val Loss: 323.218, Val Accuracy: 0.758 Train Loss: 1228.969, Train Accuracy: 0.778\n",
            "Iteration: 11700, Val Loss: 322.619, Val Accuracy: 0.756 Train Loss: 1225.036, Train Accuracy: 0.775\n",
            "Iteration: 11800, Val Loss: 322.309, Val Accuracy: 0.756 Train Loss: 1223.860, Train Accuracy: 0.773\n",
            "Iteration: 11900, Val Loss: 321.713, Val Accuracy: 0.757 Train Loss: 1221.988, Train Accuracy: 0.777\n",
            "Iteration: 12000, Val Loss: 322.057, Val Accuracy: 0.757 Train Loss: 1223.472, Train Accuracy: 0.775\n",
            "Iteration: 12100, Val Loss: 322.192, Val Accuracy: 0.756 Train Loss: 1221.509, Train Accuracy: 0.773\n",
            "Iteration: 12200, Val Loss: 321.827, Val Accuracy: 0.757 Train Loss: 1220.547, Train Accuracy: 0.775\n",
            "Iteration: 12300, Val Loss: 321.548, Val Accuracy: 0.757 Train Loss: 1218.447, Train Accuracy: 0.778\n",
            "Iteration: 12400, Val Loss: 321.172, Val Accuracy: 0.760 Train Loss: 1217.393, Train Accuracy: 0.778\n",
            "Iteration: 12500, Val Loss: 320.894, Val Accuracy: 0.758 Train Loss: 1216.855, Train Accuracy: 0.778\n",
            "Iteration: 12600, Val Loss: 323.426, Val Accuracy: 0.758 Train Loss: 1227.122, Train Accuracy: 0.782\n",
            "Iteration: 12700, Val Loss: 321.516, Val Accuracy: 0.758 Train Loss: 1218.142, Train Accuracy: 0.780\n",
            "Iteration: 12800, Val Loss: 320.887, Val Accuracy: 0.756 Train Loss: 1215.638, Train Accuracy: 0.776\n",
            "Iteration: 12900, Val Loss: 320.850, Val Accuracy: 0.758 Train Loss: 1214.672, Train Accuracy: 0.778\n",
            "Iteration: 13000, Val Loss: 320.812, Val Accuracy: 0.758 Train Loss: 1213.496, Train Accuracy: 0.776\n",
            "Iteration: 13100, Val Loss: 320.385, Val Accuracy: 0.759 Train Loss: 1211.870, Train Accuracy: 0.778\n",
            "Iteration: 13200, Val Loss: 320.353, Val Accuracy: 0.760 Train Loss: 1211.116, Train Accuracy: 0.780\n",
            "Iteration: 13300, Val Loss: 320.287, Val Accuracy: 0.757 Train Loss: 1211.329, Train Accuracy: 0.776\n",
            "Iteration: 13400, Val Loss: 320.533, Val Accuracy: 0.757 Train Loss: 1211.039, Train Accuracy: 0.777\n",
            "Iteration: 13500, Val Loss: 322.506, Val Accuracy: 0.753 Train Loss: 1217.276, Train Accuracy: 0.771\n",
            "Iteration: 13600, Val Loss: 320.408, Val Accuracy: 0.759 Train Loss: 1208.328, Train Accuracy: 0.779\n",
            "Iteration: 13700, Val Loss: 322.301, Val Accuracy: 0.758 Train Loss: 1217.516, Train Accuracy: 0.781\n",
            "Iteration: 13800, Val Loss: 320.150, Val Accuracy: 0.758 Train Loss: 1207.917, Train Accuracy: 0.776\n",
            "Iteration: 13900, Val Loss: 319.914, Val Accuracy: 0.758 Train Loss: 1206.514, Train Accuracy: 0.779\n",
            "Iteration: 14000, Val Loss: 319.903, Val Accuracy: 0.758 Train Loss: 1205.909, Train Accuracy: 0.778\n",
            "Iteration: 14100, Val Loss: 319.942, Val Accuracy: 0.759 Train Loss: 1206.629, Train Accuracy: 0.780\n",
            "Iteration: 14200, Val Loss: 320.960, Val Accuracy: 0.754 Train Loss: 1209.767, Train Accuracy: 0.773\n",
            "Iteration: 14300, Val Loss: 319.497, Val Accuracy: 0.759 Train Loss: 1203.535, Train Accuracy: 0.781\n",
            "Iteration: 14400, Val Loss: 320.401, Val Accuracy: 0.756 Train Loss: 1206.488, Train Accuracy: 0.775\n",
            "Iteration: 14500, Val Loss: 319.194, Val Accuracy: 0.761 Train Loss: 1203.198, Train Accuracy: 0.783\n",
            "Iteration: 14600, Val Loss: 320.641, Val Accuracy: 0.755 Train Loss: 1207.881, Train Accuracy: 0.775\n",
            "Iteration: 14700, Val Loss: 320.209, Val Accuracy: 0.760 Train Loss: 1205.185, Train Accuracy: 0.783\n",
            "Iteration: 14800, Val Loss: 318.678, Val Accuracy: 0.760 Train Loss: 1199.880, Train Accuracy: 0.782\n",
            "Iteration: 14900, Val Loss: 318.613, Val Accuracy: 0.760 Train Loss: 1198.540, Train Accuracy: 0.782\n",
            "Iteration: 15000, Val Loss: 318.672, Val Accuracy: 0.762 Train Loss: 1198.837, Train Accuracy: 0.783\n",
            "Iteration: 15100, Val Loss: 320.871, Val Accuracy: 0.756 Train Loss: 1207.820, Train Accuracy: 0.774\n",
            "Iteration: 15200, Val Loss: 321.077, Val Accuracy: 0.760 Train Loss: 1209.637, Train Accuracy: 0.786\n",
            "Iteration: 15300, Val Loss: 318.135, Val Accuracy: 0.759 Train Loss: 1195.934, Train Accuracy: 0.782\n",
            "Iteration: 15400, Val Loss: 319.055, Val Accuracy: 0.758 Train Loss: 1199.671, Train Accuracy: 0.777\n",
            "Iteration: 15500, Val Loss: 323.049, Val Accuracy: 0.760 Train Loss: 1216.362, Train Accuracy: 0.785\n",
            "Iteration: 15600, Val Loss: 318.256, Val Accuracy: 0.760 Train Loss: 1196.083, Train Accuracy: 0.781\n",
            "Iteration: 15700, Val Loss: 318.184, Val Accuracy: 0.761 Train Loss: 1195.264, Train Accuracy: 0.784\n",
            "Iteration: 15800, Val Loss: 321.964, Val Accuracy: 0.762 Train Loss: 1210.606, Train Accuracy: 0.787\n",
            "Iteration: 15900, Val Loss: 318.804, Val Accuracy: 0.763 Train Loss: 1198.208, Train Accuracy: 0.786\n",
            "Iteration: 16000, Val Loss: 318.620, Val Accuracy: 0.758 Train Loss: 1194.423, Train Accuracy: 0.779\n",
            "Iteration: 16100, Val Loss: 318.634, Val Accuracy: 0.762 Train Loss: 1194.378, Train Accuracy: 0.785\n",
            "Iteration: 16200, Val Loss: 320.679, Val Accuracy: 0.756 Train Loss: 1200.451, Train Accuracy: 0.776\n",
            "Iteration: 16300, Val Loss: 317.826, Val Accuracy: 0.760"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d9e9da7aec03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.max(outputs, 1)[1].to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-4866067a2d2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reshape(-1, 15, 600).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H0qdUSfzu9LY",
        "outputId": "f0bbf43b-10fe-4110-a8c1-a83e0048206d"
      },
      "source": [
        "learning_rate = 0.01\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%100 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 16400, Val Loss: 317.228, Val Accuracy: 0.762 Train Loss: 1187.765, Train Accuracy: 0.785\n",
            "Iteration: 16500, Val Loss: 317.187, Val Accuracy: 0.761 Train Loss: 1186.805, Train Accuracy: 0.782\n",
            "Iteration: 16600, Val Loss: 316.737, Val Accuracy: 0.763 Train Loss: 1184.663, Train Accuracy: 0.785\n",
            "Iteration: 16700, Val Loss: 316.591, Val Accuracy: 0.761 Train Loss: 1184.125, Train Accuracy: 0.785\n",
            "Iteration: 16800, Val Loss: 316.283, Val Accuracy: 0.763 Train Loss: 1182.621, Train Accuracy: 0.787\n",
            "Iteration: 16900, Val Loss: 316.361, Val Accuracy: 0.762 Train Loss: 1182.467, Train Accuracy: 0.785\n",
            "Iteration: 17000, Val Loss: 316.491, Val Accuracy: 0.762 Train Loss: 1183.298, Train Accuracy: 0.788\n",
            "Iteration: 17100, Val Loss: 315.933, Val Accuracy: 0.763 Train Loss: 1180.707, Train Accuracy: 0.786\n",
            "Iteration: 17200, Val Loss: 315.826, Val Accuracy: 0.763 Train Loss: 1180.125, Train Accuracy: 0.787\n",
            "Iteration: 17300, Val Loss: 316.092, Val Accuracy: 0.762 Train Loss: 1180.400, Train Accuracy: 0.784\n",
            "Iteration: 17400, Val Loss: 315.881, Val Accuracy: 0.763 Train Loss: 1179.716, Train Accuracy: 0.788\n",
            "Iteration: 17500, Val Loss: 315.861, Val Accuracy: 0.763 Train Loss: 1179.262, Train Accuracy: 0.786\n",
            "Iteration: 17600, Val Loss: 316.067, Val Accuracy: 0.764 Train Loss: 1180.123, Train Accuracy: 0.789\n",
            "Iteration: 17700, Val Loss: 315.972, Val Accuracy: 0.764 Train Loss: 1178.891, Train Accuracy: 0.787\n",
            "Iteration: 17800, Val Loss: 316.233, Val Accuracy: 0.764 Train Loss: 1179.837, Train Accuracy: 0.788\n",
            "Iteration: 17900, Val Loss: 316.083, Val Accuracy: 0.762 Train Loss: 1179.396, Train Accuracy: 0.785\n",
            "Iteration: 18000, Val Loss: 315.744, Val Accuracy: 0.764 Train Loss: 1177.919, Train Accuracy: 0.788\n",
            "Iteration: 18100, Val Loss: 315.647, Val Accuracy: 0.763 Train Loss: 1177.211, Train Accuracy: 0.787\n",
            "Iteration: 18200, Val Loss: 315.554, Val Accuracy: 0.764 Train Loss: 1176.602, Train Accuracy: 0.787\n",
            "Iteration: 18300, Val Loss: 315.712, Val Accuracy: 0.763 Train Loss: 1177.072, Train Accuracy: 0.787\n",
            "Iteration: 18400, Val Loss: 316.392, Val Accuracy: 0.765 Train Loss: 1180.161, Train Accuracy: 0.791\n",
            "Iteration: 18500, Val Loss: 315.650, Val Accuracy: 0.764 Train Loss: 1176.598, Train Accuracy: 0.790\n",
            "Iteration: 18600, Val Loss: 315.233, Val Accuracy: 0.764 Train Loss: 1174.614, Train Accuracy: 0.788\n",
            "Iteration: 18700, Val Loss: 315.787, Val Accuracy: 0.762 Train Loss: 1176.955, Train Accuracy: 0.786\n",
            "Iteration: 18800, Val Loss: 315.148, Val Accuracy: 0.765 Train Loss: 1173.908, Train Accuracy: 0.790\n",
            "Iteration: 18900, Val Loss: 315.264, Val Accuracy: 0.763 Train Loss: 1174.045, Train Accuracy: 0.787\n",
            "Iteration: 19000, Val Loss: 315.046, Val Accuracy: 0.764 Train Loss: 1172.939, Train Accuracy: 0.788\n",
            "Iteration: 19100, Val Loss: 315.048, Val Accuracy: 0.764 Train Loss: 1172.828, Train Accuracy: 0.790\n",
            "Iteration: 19200, Val Loss: 315.042, Val Accuracy: 0.765 Train Loss: 1172.872, Train Accuracy: 0.791\n",
            "Iteration: 19300, Val Loss: 315.157, Val Accuracy: 0.763 Train Loss: 1173.135, Train Accuracy: 0.787\n",
            "Iteration: 19400, Val Loss: 314.824, Val Accuracy: 0.764 Train Loss: 1171.749, Train Accuracy: 0.789\n",
            "Iteration: 19500, Val Loss: 314.899, Val Accuracy: 0.764 Train Loss: 1171.942, Train Accuracy: 0.789\n",
            "Iteration: 19600, Val Loss: 314.769, Val Accuracy: 0.763 Train Loss: 1171.305, Train Accuracy: 0.789\n",
            "Iteration: 19700, Val Loss: 314.715, Val Accuracy: 0.765 Train Loss: 1171.171, Train Accuracy: 0.790\n",
            "Iteration: 19800, Val Loss: 314.744, Val Accuracy: 0.765 Train Loss: 1171.372, Train Accuracy: 0.791\n",
            "Iteration: 19900, Val Loss: 314.948, Val Accuracy: 0.763 Train Loss: 1171.361, Train Accuracy: 0.787\n",
            "Iteration: 20000, Val Loss: 314.608, Val Accuracy: 0.765 Train Loss: 1170.136, Train Accuracy: 0.790\n",
            "Iteration: 20100, Val Loss: 314.707, Val Accuracy: 0.765 Train Loss: 1170.376, Train Accuracy: 0.789\n",
            "Iteration: 20200, Val Loss: 314.880, Val Accuracy: 0.764 Train Loss: 1170.555, Train Accuracy: 0.787\n",
            "Iteration: 20300, Val Loss: 314.900, Val Accuracy: 0.764 Train Loss: 1170.035, Train Accuracy: 0.788\n",
            "Iteration: 20400, Val Loss: 314.885, Val Accuracy: 0.764 Train Loss: 1170.013, Train Accuracy: 0.790\n",
            "Iteration: 20500, Val Loss: 314.724, Val Accuracy: 0.765 Train Loss: 1169.696, Train Accuracy: 0.789\n",
            "Iteration: 20600, Val Loss: 314.693, Val Accuracy: 0.765 Train Loss: 1169.225, Train Accuracy: 0.790\n",
            "Iteration: 20700, Val Loss: 314.526, Val Accuracy: 0.766 Train Loss: 1168.582, Train Accuracy: 0.791\n",
            "Iteration: 20800, Val Loss: 314.592, Val Accuracy: 0.765 Train Loss: 1168.695, Train Accuracy: 0.791\n",
            "Iteration: 20900, Val Loss: 314.723, Val Accuracy: 0.764 Train Loss: 1168.894, Train Accuracy: 0.789\n",
            "Iteration: 21000, Val Loss: 314.532, Val Accuracy: 0.765 Train Loss: 1168.240, Train Accuracy: 0.791\n",
            "Iteration: 21100, Val Loss: 314.580, Val Accuracy: 0.765 Train Loss: 1168.395, Train Accuracy: 0.792\n",
            "Iteration: 21200, Val Loss: 314.484, Val Accuracy: 0.764 Train Loss: 1167.602, Train Accuracy: 0.789\n",
            "Iteration: 21300, Val Loss: 314.375, Val Accuracy: 0.766 Train Loss: 1167.786, Train Accuracy: 0.792\n",
            "Iteration: 21400, Val Loss: 314.417, Val Accuracy: 0.764 Train Loss: 1167.084, Train Accuracy: 0.790\n",
            "Iteration: 21500, Val Loss: 314.306, Val Accuracy: 0.765 Train Loss: 1166.533, Train Accuracy: 0.792\n",
            "Iteration: 21600, Val Loss: 314.829, Val Accuracy: 0.762 Train Loss: 1168.152, Train Accuracy: 0.787\n",
            "Iteration: 21700, Val Loss: 314.326, Val Accuracy: 0.765 Train Loss: 1166.297, Train Accuracy: 0.792\n",
            "Iteration: 21800, Val Loss: 314.331, Val Accuracy: 0.766 Train Loss: 1166.643, Train Accuracy: 0.793\n",
            "Iteration: 21900, Val Loss: 315.081, Val Accuracy: 0.766 Train Loss: 1169.949, Train Accuracy: 0.795\n",
            "Iteration: 22000, Val Loss: 314.076, Val Accuracy: 0.765 Train Loss: 1165.316, Train Accuracy: 0.790\n",
            "Iteration: 22100, Val Loss: 314.183, Val Accuracy: 0.765 Train Loss: 1165.561, Train Accuracy: 0.791\n",
            "Iteration: 22200, Val Loss: 314.079, Val Accuracy: 0.764 Train Loss: 1164.952, Train Accuracy: 0.790\n",
            "Iteration: 22300, Val Loss: 313.990, Val Accuracy: 0.765 Train Loss: 1164.585, Train Accuracy: 0.791\n",
            "Iteration: 22400, Val Loss: 314.159, Val Accuracy: 0.766 Train Loss: 1165.650, Train Accuracy: 0.794\n",
            "Iteration: 22500, Val Loss: 314.642, Val Accuracy: 0.766 Train Loss: 1167.212, Train Accuracy: 0.794\n",
            "Iteration: 22600, Val Loss: 313.906, Val Accuracy: 0.765 Train Loss: 1163.885, Train Accuracy: 0.791\n",
            "Iteration: 22700, Val Loss: 313.981, Val Accuracy: 0.765 Train Loss: 1164.065, Train Accuracy: 0.791\n",
            "Iteration: 22800, Val Loss: 314.131, Val Accuracy: 0.766 Train Loss: 1164.306, Train Accuracy: 0.793\n",
            "Iteration: 22900, Val Loss: 314.058, Val Accuracy: 0.765 Train Loss: 1163.296, Train Accuracy: 0.791\n",
            "Iteration: 23000, Val Loss: 314.448, Val Accuracy: 0.766 Train Loss: 1165.146, Train Accuracy: 0.794\n",
            "Iteration: 23100, Val Loss: 313.932, Val Accuracy: 0.765 Train Loss: 1163.090, Train Accuracy: 0.791\n",
            "Iteration: 23200, Val Loss: 314.019, Val Accuracy: 0.767 Train Loss: 1163.285, Train Accuracy: 0.793\n",
            "Iteration: 23300, Val Loss: 314.036, Val Accuracy: 0.766 Train Loss: 1163.166, Train Accuracy: 0.794\n",
            "Iteration: 23400, Val Loss: 313.974, Val Accuracy: 0.765 Train Loss: 1162.653, Train Accuracy: 0.790\n",
            "Iteration: 23500, Val Loss: 313.880, Val Accuracy: 0.765 Train Loss: 1162.532, Train Accuracy: 0.792\n",
            "Iteration: 23600, Val Loss: 313.882, Val Accuracy: 0.765 Train Loss: 1162.125, Train Accuracy: 0.791\n",
            "Iteration: 23700, Val Loss: 313.819, Val Accuracy: 0.765 Train Loss: 1161.899, Train Accuracy: 0.791\n",
            "Iteration: 23800, Val Loss: 313.730, Val Accuracy: 0.766 Train Loss: 1161.710, Train Accuracy: 0.793\n",
            "Iteration: 23900, Val Loss: 313.810, Val Accuracy: 0.765 Train Loss: 1162.255, Train Accuracy: 0.792\n",
            "Iteration: 24000, Val Loss: 314.015, Val Accuracy: 0.764 Train Loss: 1162.135, Train Accuracy: 0.790\n",
            "Iteration: 24100, Val Loss: 313.778, Val Accuracy: 0.766 Train Loss: 1161.396, Train Accuracy: 0.794\n",
            "Iteration: 24200, Val Loss: 313.632, Val Accuracy: 0.766 Train Loss: 1160.406, Train Accuracy: 0.793\n",
            "Iteration: 24300, Val Loss: 313.745, Val Accuracy: 0.766 Train Loss: 1161.064, Train Accuracy: 0.794\n",
            "Iteration: 24400, Val Loss: 313.509, Val Accuracy: 0.766 Train Loss: 1160.165, Train Accuracy: 0.793\n",
            "Iteration: 24500, Val Loss: 313.968, Val Accuracy: 0.767 Train Loss: 1162.316, Train Accuracy: 0.796\n",
            "Iteration: 24600, Val Loss: 313.508, Val Accuracy: 0.765 Train Loss: 1159.879, Train Accuracy: 0.792\n",
            "Iteration: 24700, Val Loss: 313.528, Val Accuracy: 0.764 Train Loss: 1159.997, Train Accuracy: 0.792\n",
            "Iteration: 24800, Val Loss: 313.437, Val Accuracy: 0.765 Train Loss: 1159.448, Train Accuracy: 0.792\n",
            "Iteration: 24900, Val Loss: 313.483, Val Accuracy: 0.767 Train Loss: 1159.588, Train Accuracy: 0.794\n",
            "Iteration: 25000, Val Loss: 313.379, Val Accuracy: 0.766 Train Loss: 1158.980, Train Accuracy: 0.791\n",
            "Iteration: 25100, Val Loss: 313.338, Val Accuracy: 0.766 Train Loss: 1158.563, Train Accuracy: 0.792\n",
            "Iteration: 25200, Val Loss: 313.389, Val Accuracy: 0.765 Train Loss: 1158.726, Train Accuracy: 0.791\n",
            "Iteration: 25300, Val Loss: 313.742, Val Accuracy: 0.764 Train Loss: 1159.927, Train Accuracy: 0.790\n",
            "Iteration: 25400, Val Loss: 313.683, Val Accuracy: 0.765 Train Loss: 1159.142, Train Accuracy: 0.790\n",
            "Iteration: 25500, Val Loss: 313.546, Val Accuracy: 0.765 Train Loss: 1158.153, Train Accuracy: 0.791\n",
            "Iteration: 25600, Val Loss: 313.586, Val Accuracy: 0.766 Train Loss: 1158.647, Train Accuracy: 0.794\n",
            "Iteration: 25700, Val Loss: 313.365, Val Accuracy: 0.766 Train Loss: 1157.678, Train Accuracy: 0.792\n",
            "Iteration: 25800, Val Loss: 313.359, Val Accuracy: 0.767 Train Loss: 1157.673, Train Accuracy: 0.794\n",
            "Iteration: 25900, Val Loss: 313.259, Val Accuracy: 0.766 Train Loss: 1157.080, Train Accuracy: 0.794\n",
            "Iteration: 26000, Val Loss: 313.289, Val Accuracy: 0.766 Train Loss: 1157.269, Train Accuracy: 0.794\n",
            "Iteration: 26100, Val Loss: 313.270, Val Accuracy: 0.765 Train Loss: 1156.974, Train Accuracy: 0.793\n",
            "Iteration: 26200, Val Loss: 313.268, Val Accuracy: 0.766 Train Loss: 1156.897, Train Accuracy: 0.794\n",
            "Iteration: 26300, Val Loss: 313.227, Val Accuracy: 0.765 Train Loss: 1156.466, Train Accuracy: 0.792\n",
            "Iteration: 26400, Val Loss: 313.214, Val Accuracy: 0.767 Train Loss: 1156.827, Train Accuracy: 0.795\n",
            "Iteration: 26500, Val Loss: 313.782, Val Accuracy: 0.764 Train Loss: 1158.899, Train Accuracy: 0.790\n",
            "Iteration: 26600, Val Loss: 313.208, Val Accuracy: 0.766 Train Loss: 1156.238, Train Accuracy: 0.794\n",
            "Iteration: 26700, Val Loss: 313.046, Val Accuracy: 0.766 Train Loss: 1155.639, Train Accuracy: 0.794\n",
            "Iteration: 26800, Val Loss: 313.039, Val Accuracy: 0.767 Train Loss: 1155.284, Train Accuracy: 0.794\n",
            "Iteration: 26900, Val Loss: 313.098, Val Accuracy: 0.766 Train Loss: 1155.380, Train Accuracy: 0.793\n",
            "Iteration: 27000, Val Loss: 313.473, Val Accuracy: 0.764 Train Loss: 1156.996, Train Accuracy: 0.791\n",
            "Iteration: 27100, Val Loss: 313.352, Val Accuracy: 0.767 Train Loss: 1157.231, Train Accuracy: 0.797\n",
            "Iteration: 27200, Val Loss: 312.891, Val Accuracy: 0.766 Train Loss: 1154.703, Train Accuracy: 0.793\n",
            "Iteration: 27300, Val Loss: 313.040, Val Accuracy: 0.765 Train Loss: 1155.168, Train Accuracy: 0.792\n",
            "Iteration: 27400, Val Loss: 313.498, Val Accuracy: 0.767 Train Loss: 1157.313, Train Accuracy: 0.796\n",
            "Iteration: 27500, Val Loss: 312.848, Val Accuracy: 0.767 Train Loss: 1154.438, Train Accuracy: 0.795\n",
            "Iteration: 27600, Val Loss: 312.804, Val Accuracy: 0.767 Train Loss: 1153.990, Train Accuracy: 0.793\n",
            "Iteration: 27700, Val Loss: 314.104, Val Accuracy: 0.768 Train Loss: 1159.460, Train Accuracy: 0.798\n",
            "Iteration: 27800, Val Loss: 313.206, Val Accuracy: 0.768 Train Loss: 1155.796, Train Accuracy: 0.797\n",
            "Iteration: 27900, Val Loss: 314.385, Val Accuracy: 0.761 Train Loss: 1159.340, Train Accuracy: 0.787\n",
            "Iteration: 28000, Val Loss: 312.971, Val Accuracy: 0.767 Train Loss: 1153.778, Train Accuracy: 0.795\n",
            "Iteration: 28100, Val Loss: 314.295, Val Accuracy: 0.762 Train Loss: 1158.000, Train Accuracy: 0.787\n",
            "Iteration: 28200, Val Loss: 312.947, Val Accuracy: 0.766 Train Loss: 1152.989, Train Accuracy: 0.793\n",
            "Iteration: 28300, Val Loss: 312.789, Val Accuracy: 0.767 Train Loss: 1152.778, Train Accuracy: 0.795\n",
            "Iteration: 28400, Val Loss: 312.762, Val Accuracy: 0.767 Train Loss: 1152.640, Train Accuracy: 0.795\n",
            "Iteration: 28500, Val Loss: 312.837, Val Accuracy: 0.767 Train Loss: 1152.814, Train Accuracy: 0.796\n",
            "Iteration: 28600, Val Loss: 312.789, Val Accuracy: 0.766 Train Loss: 1152.469, Train Accuracy: 0.795\n",
            "Iteration: 28700, Val Loss: 313.359, Val Accuracy: 0.764 Train Loss: 1154.329, Train Accuracy: 0.790\n",
            "Iteration: 28800, Val Loss: 313.248, Val Accuracy: 0.767 Train Loss: 1154.316, Train Accuracy: 0.797\n",
            "Iteration: 28900, Val Loss: 312.887, Val Accuracy: 0.767 Train Loss: 1152.639, Train Accuracy: 0.796\n",
            "Iteration: 29000, Val Loss: 312.605, Val Accuracy: 0.767 Train Loss: 1151.793, Train Accuracy: 0.796\n",
            "Iteration: 29100, Val Loss: 312.675, Val Accuracy: 0.767 Train Loss: 1152.089, Train Accuracy: 0.796\n",
            "Iteration: 29200, Val Loss: 312.564, Val Accuracy: 0.767 Train Loss: 1151.098, Train Accuracy: 0.795\n",
            "Iteration: 29300, Val Loss: 312.566, Val Accuracy: 0.766 Train Loss: 1150.875, Train Accuracy: 0.794\n",
            "Iteration: 29400, Val Loss: 312.746, Val Accuracy: 0.768 Train Loss: 1151.706, Train Accuracy: 0.797\n",
            "Iteration: 29500, Val Loss: 312.582, Val Accuracy: 0.767 Train Loss: 1150.761, Train Accuracy: 0.794\n",
            "Iteration: 29600, Val Loss: 312.502, Val Accuracy: 0.766 Train Loss: 1150.771, Train Accuracy: 0.795\n",
            "Iteration: 29700, Val Loss: 312.418, Val Accuracy: 0.767 Train Loss: 1150.641, Train Accuracy: 0.796\n",
            "Iteration: 29800, Val Loss: 312.636, Val Accuracy: 0.765 Train Loss: 1150.977, Train Accuracy: 0.793\n",
            "Iteration: 29900, Val Loss: 312.552, Val Accuracy: 0.765 Train Loss: 1150.669, Train Accuracy: 0.793\n",
            "Iteration: 30000, Val Loss: 312.553, Val Accuracy: 0.766 Train Loss: 1150.487, Train Accuracy: 0.793\n",
            "Iteration: 30100, Val Loss: 312.305, Val Accuracy: 0.767 Train Loss: 1149.722, Train Accuracy: 0.796\n",
            "Iteration: 30200, Val Loss: 312.336, Val Accuracy: 0.767 Train Loss: 1149.621, Train Accuracy: 0.796\n",
            "Iteration: 30300, Val Loss: 312.217, Val Accuracy: 0.767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2da8c8229f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.max(outputs, 1)[1].to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-4866067a2d2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-4866067a2d2a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    259\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 260\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XU0J90LAWL9l",
        "outputId": "c21e5b96-7981-4baf-c395-f1aeb5bbf8af"
      },
      "source": [
        "learning_rate = 0.01\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%500 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10500, Val Loss: 347.786, Val Accuracy: 0.730 Train Loss: 1383.547, Train Accuracy: 0.734\n",
            "Iteration: 11000, Val Loss: 347.314, Val Accuracy: 0.732 Train Loss: 1381.439, Train Accuracy: 0.735\n",
            "Iteration: 11500, Val Loss: 347.236, Val Accuracy: 0.733 Train Loss: 1381.081, Train Accuracy: 0.736\n",
            "Iteration: 12000, Val Loss: 347.169, Val Accuracy: 0.734 Train Loss: 1380.869, Train Accuracy: 0.737\n",
            "Iteration: 12500, Val Loss: 346.979, Val Accuracy: 0.734 Train Loss: 1380.051, Train Accuracy: 0.737\n",
            "Iteration: 13000, Val Loss: 347.136, Val Accuracy: 0.731 Train Loss: 1380.198, Train Accuracy: 0.735\n",
            "Iteration: 13500, Val Loss: 346.556, Val Accuracy: 0.734 Train Loss: 1378.314, Train Accuracy: 0.736\n",
            "Iteration: 14000, Val Loss: 346.663, Val Accuracy: 0.733 Train Loss: 1378.242, Train Accuracy: 0.737\n",
            "Iteration: 14500, Val Loss: 346.600, Val Accuracy: 0.733 Train Loss: 1377.871, Train Accuracy: 0.736\n",
            "Iteration: 15000, Val Loss: 346.655, Val Accuracy: 0.733 Train Loss: 1378.222, Train Accuracy: 0.736\n",
            "Iteration: 15500, Val Loss: 346.493, Val Accuracy: 0.734 Train Loss: 1377.525, Train Accuracy: 0.738\n",
            "Iteration: 16000, Val Loss: 346.388, Val Accuracy: 0.735 Train Loss: 1377.161, Train Accuracy: 0.739\n",
            "Iteration: 16500, Val Loss: 346.222, Val Accuracy: 0.733 Train Loss: 1376.320, Train Accuracy: 0.737\n",
            "Iteration: 17000, Val Loss: 346.345, Val Accuracy: 0.734 Train Loss: 1376.636, Train Accuracy: 0.738\n",
            "Iteration: 17500, Val Loss: 346.311, Val Accuracy: 0.734 Train Loss: 1376.307, Train Accuracy: 0.737\n",
            "Iteration: 18000, Val Loss: 346.175, Val Accuracy: 0.734 Train Loss: 1375.843, Train Accuracy: 0.737\n",
            "Iteration: 18500, Val Loss: 345.961, Val Accuracy: 0.734 Train Loss: 1375.241, Train Accuracy: 0.737\n",
            "Iteration: 19000, Val Loss: 346.586, Val Accuracy: 0.731 Train Loss: 1377.030, Train Accuracy: 0.735\n",
            "Iteration: 19500, Val Loss: 346.304, Val Accuracy: 0.733 Train Loss: 1375.962, Train Accuracy: 0.737\n",
            "Iteration: 20000, Val Loss: 346.147, Val Accuracy: 0.735 Train Loss: 1375.535, Train Accuracy: 0.738\n",
            "Iteration: 20500, Val Loss: 346.099, Val Accuracy: 0.735 Train Loss: 1375.838, Train Accuracy: 0.739\n",
            "Iteration: 21000, Val Loss: 346.124, Val Accuracy: 0.734 Train Loss: 1376.358, Train Accuracy: 0.738\n",
            "Iteration: 21500, Val Loss: 345.795, Val Accuracy: 0.734 Train Loss: 1374.054, Train Accuracy: 0.737\n",
            "Iteration: 22000, Val Loss: 345.937, Val Accuracy: 0.734 Train Loss: 1374.638, Train Accuracy: 0.737\n",
            "Iteration: 22500, Val Loss: 345.878, Val Accuracy: 0.735 Train Loss: 1374.396, Train Accuracy: 0.738\n",
            "Iteration: 23000, Val Loss: 345.750, Val Accuracy: 0.736 Train Loss: 1374.405, Train Accuracy: 0.739\n",
            "Iteration: 23500, Val Loss: 345.629, Val Accuracy: 0.735 Train Loss: 1373.604, Train Accuracy: 0.738\n",
            "Iteration: 24000, Val Loss: 345.871, Val Accuracy: 0.736 Train Loss: 1374.427, Train Accuracy: 0.739\n",
            "Iteration: 24500, Val Loss: 345.707, Val Accuracy: 0.735 Train Loss: 1373.601, Train Accuracy: 0.739\n",
            "Iteration: 25000, Val Loss: 345.698, Val Accuracy: 0.734 Train Loss: 1373.478, Train Accuracy: 0.738\n",
            "Iteration: 25500, Val Loss: 345.753, Val Accuracy: 0.733 Train Loss: 1373.848, Train Accuracy: 0.737\n",
            "Iteration: 26000, Val Loss: 345.717, Val Accuracy: 0.736 Train Loss: 1373.756, Train Accuracy: 0.739\n",
            "Iteration: 26500, Val Loss: 345.825, Val Accuracy: 0.732 Train Loss: 1374.031, Train Accuracy: 0.736\n",
            "Iteration: 27000, Val Loss: 345.853, Val Accuracy: 0.735 Train Loss: 1374.334, Train Accuracy: 0.739\n",
            "Iteration: 27500, Val Loss: 345.717, Val Accuracy: 0.735 Train Loss: 1373.778, Train Accuracy: 0.739\n",
            "Iteration: 28000, Val Loss: 345.663, Val Accuracy: 0.735 Train Loss: 1373.549, Train Accuracy: 0.739\n",
            "Iteration: 28500, Val Loss: 346.017, Val Accuracy: 0.732 Train Loss: 1374.548, Train Accuracy: 0.736\n",
            "Iteration: 29000, Val Loss: 345.474, Val Accuracy: 0.736 Train Loss: 1372.784, Train Accuracy: 0.739\n",
            "Iteration: 29500, Val Loss: 345.635, Val Accuracy: 0.735 Train Loss: 1372.961, Train Accuracy: 0.739\n",
            "Iteration: 30000, Val Loss: 345.566, Val Accuracy: 0.735 Train Loss: 1372.864, Train Accuracy: 0.738\n",
            "Iteration: 30500, Val Loss: 345.703, Val Accuracy: 0.735 Train Loss: 1373.283, Train Accuracy: 0.738\n",
            "Iteration: 31000, Val Loss: 345.582, Val Accuracy: 0.735 Train Loss: 1372.818, Train Accuracy: 0.739\n",
            "Iteration: 31500, Val Loss: 345.416, Val Accuracy: 0.734 Train Loss: 1372.209, Train Accuracy: 0.738\n",
            "Iteration: 32000, Val Loss: 345.433, Val Accuracy: 0.734 Train Loss: 1372.267, Train Accuracy: 0.738\n",
            "Iteration: 32500, Val Loss: 346.118, Val Accuracy: 0.736 Train Loss: 1375.195, Train Accuracy: 0.740\n",
            "Iteration: 33000, Val Loss: 345.801, Val Accuracy: 0.736 Train Loss: 1373.629, Train Accuracy: 0.740\n",
            "Iteration: 33500, Val Loss: 345.478, Val Accuracy: 0.734 Train Loss: 1372.364, Train Accuracy: 0.738\n",
            "Iteration: 34000, Val Loss: 345.372, Val Accuracy: 0.736 Train Loss: 1372.385, Train Accuracy: 0.739\n",
            "Iteration: 34500, Val Loss: 347.408, Val Accuracy: 0.727 Train Loss: 1379.729, Train Accuracy: 0.732\n",
            "Iteration: 35000, Val Loss: 345.576, Val Accuracy: 0.735 Train Loss: 1372.470, Train Accuracy: 0.739\n",
            "Iteration: 35500, Val Loss: 345.531, Val Accuracy: 0.735 Train Loss: 1372.337, Train Accuracy: 0.739\n",
            "Iteration: 36000, Val Loss: 345.298, Val Accuracy: 0.735 Train Loss: 1371.839, Train Accuracy: 0.739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-6e4ceb1a6a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#Variable(images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;31m#Variable(labels.view(len(labels),1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss_list_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-661021bca2e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-661021bca2e6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;31m# Handle the non-full backward hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_full_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wtreJBkAj-wk",
        "outputId": "823195fc-598b-44a3-f7c7-c505aa6b2415"
      },
      "source": [
        "learning_rate = 0.0005\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%500 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 61500, Val Loss: 343.217, Val Accuracy: 0.737 Train Loss: 1362.633, Train Accuracy: 0.742\n",
            "Iteration: 62000, Val Loss: 343.210, Val Accuracy: 0.737 Train Loss: 1362.591, Train Accuracy: 0.741\n",
            "Iteration: 62500, Val Loss: 343.198, Val Accuracy: 0.737 Train Loss: 1362.551, Train Accuracy: 0.742\n",
            "Iteration: 63000, Val Loss: 343.215, Val Accuracy: 0.737 Train Loss: 1362.584, Train Accuracy: 0.741\n",
            "Iteration: 63500, Val Loss: 343.223, Val Accuracy: 0.738 Train Loss: 1362.651, Train Accuracy: 0.742\n",
            "Iteration: 64000, Val Loss: 343.205, Val Accuracy: 0.737 Train Loss: 1362.564, Train Accuracy: 0.742\n",
            "Iteration: 64500, Val Loss: 343.239, Val Accuracy: 0.737 Train Loss: 1362.680, Train Accuracy: 0.741\n",
            "Iteration: 65000, Val Loss: 343.192, Val Accuracy: 0.738 Train Loss: 1362.539, Train Accuracy: 0.742\n",
            "Iteration: 65500, Val Loss: 343.197, Val Accuracy: 0.737 Train Loss: 1362.542, Train Accuracy: 0.742\n",
            "Iteration: 66000, Val Loss: 343.211, Val Accuracy: 0.737 Train Loss: 1362.555, Train Accuracy: 0.741\n",
            "Iteration: 66500, Val Loss: 343.220, Val Accuracy: 0.737 Train Loss: 1362.604, Train Accuracy: 0.741\n",
            "Iteration: 67000, Val Loss: 343.202, Val Accuracy: 0.737 Train Loss: 1362.554, Train Accuracy: 0.741\n",
            "Iteration: 67500, Val Loss: 343.185, Val Accuracy: 0.737 Train Loss: 1362.501, Train Accuracy: 0.742\n",
            "Iteration: 68000, Val Loss: 343.191, Val Accuracy: 0.738 Train Loss: 1362.517, Train Accuracy: 0.742\n",
            "Iteration: 68500, Val Loss: 343.217, Val Accuracy: 0.738 Train Loss: 1362.667, Train Accuracy: 0.742\n",
            "Iteration: 69000, Val Loss: 343.209, Val Accuracy: 0.737 Train Loss: 1362.571, Train Accuracy: 0.742\n",
            "Iteration: 69500, Val Loss: 343.212, Val Accuracy: 0.737 Train Loss: 1362.573, Train Accuracy: 0.741\n",
            "Iteration: 70000, Val Loss: 343.180, Val Accuracy: 0.737 Train Loss: 1362.495, Train Accuracy: 0.742\n",
            "Iteration: 70500, Val Loss: 343.208, Val Accuracy: 0.737 Train Loss: 1362.553, Train Accuracy: 0.741\n",
            "Iteration: 71000, Val Loss: 343.192, Val Accuracy: 0.738 Train Loss: 1362.526, Train Accuracy: 0.742\n",
            "Iteration: 71500, Val Loss: 343.229, Val Accuracy: 0.737 Train Loss: 1362.638, Train Accuracy: 0.741\n",
            "Iteration: 72000, Val Loss: 343.206, Val Accuracy: 0.738 Train Loss: 1362.606, Train Accuracy: 0.742\n",
            "Iteration: 72500, Val Loss: 343.183, Val Accuracy: 0.738 Train Loss: 1362.485, Train Accuracy: 0.741\n",
            "Iteration: 73000, Val Loss: 343.201, Val Accuracy: 0.737 Train Loss: 1362.532, Train Accuracy: 0.741\n",
            "Iteration: 73500, Val Loss: 343.193, Val Accuracy: 0.738 Train Loss: 1362.513, Train Accuracy: 0.742\n",
            "Iteration: 74000, Val Loss: 343.196, Val Accuracy: 0.738 Train Loss: 1362.511, Train Accuracy: 0.742\n",
            "Iteration: 74500, Val Loss: 343.189, Val Accuracy: 0.738 Train Loss: 1362.510, Train Accuracy: 0.742\n",
            "Iteration: 75000, Val Loss: 343.176, Val Accuracy: 0.738 Train Loss: 1362.470, Train Accuracy: 0.742\n",
            "Iteration: 75500, Val Loss: 343.220, Val Accuracy: 0.737 Train Loss: 1362.590, Train Accuracy: 0.741\n",
            "Iteration: 76000, Val Loss: 343.192, Val Accuracy: 0.738 Train Loss: 1362.486, Train Accuracy: 0.742\n",
            "Iteration: 76500, Val Loss: 343.196, Val Accuracy: 0.738 Train Loss: 1362.529, Train Accuracy: 0.742\n",
            "Iteration: 77000, Val Loss: 343.185, Val Accuracy: 0.738 Train Loss: 1362.504, Train Accuracy: 0.742\n",
            "Iteration: 77500, Val Loss: 343.170, Val Accuracy: 0.738 Train Loss: 1362.464, Train Accuracy: 0.742\n",
            "Iteration: 78000, Val Loss: 343.172, Val Accuracy: 0.738 Train Loss: 1362.437, Train Accuracy: 0.742\n",
            "Iteration: 78500, Val Loss: 343.180, Val Accuracy: 0.738 Train Loss: 1362.464, Train Accuracy: 0.742\n",
            "Iteration: 79000, Val Loss: 343.184, Val Accuracy: 0.738 Train Loss: 1362.482, Train Accuracy: 0.742\n",
            "Iteration: 79500, Val Loss: 343.189, Val Accuracy: 0.737 Train Loss: 1362.499, Train Accuracy: 0.741\n",
            "Iteration: 80000, Val Loss: 343.204, Val Accuracy: 0.737 Train Loss: 1362.544, Train Accuracy: 0.741\n",
            "Iteration: 80500, Val Loss: 343.176, Val Accuracy: 0.738 Train Loss: 1362.471, Train Accuracy: 0.742\n",
            "Iteration: 81000, Val Loss: 343.173, Val Accuracy: 0.738 Train Loss: 1362.435, Train Accuracy: 0.742\n",
            "Iteration: 81500, Val Loss: 343.178, Val Accuracy: 0.738 Train Loss: 1362.444, Train Accuracy: 0.742\n",
            "Iteration: 82000, Val Loss: 343.188, Val Accuracy: 0.738 Train Loss: 1362.479, Train Accuracy: 0.742\n",
            "Iteration: 82500, Val Loss: 343.178, Val Accuracy: 0.738 Train Loss: 1362.464, Train Accuracy: 0.742\n",
            "Iteration: 83000, Val Loss: 343.164, Val Accuracy: 0.738 Train Loss: 1362.414, Train Accuracy: 0.742\n",
            "Iteration: 83500, Val Loss: 343.173, Val Accuracy: 0.738 Train Loss: 1362.431, Train Accuracy: 0.742\n",
            "Iteration: 84000, Val Loss: 343.193, Val Accuracy: 0.738 Train Loss: 1362.551, Train Accuracy: 0.742\n",
            "Iteration: 84500, Val Loss: 343.215, Val Accuracy: 0.737 Train Loss: 1362.576, Train Accuracy: 0.741\n",
            "Iteration: 85000, Val Loss: 343.182, Val Accuracy: 0.738 Train Loss: 1362.470, Train Accuracy: 0.742\n",
            "Iteration: 85500, Val Loss: 343.167, Val Accuracy: 0.738 Train Loss: 1362.427, Train Accuracy: 0.742\n",
            "Iteration: 86000, Val Loss: 343.208, Val Accuracy: 0.737 Train Loss: 1362.530, Train Accuracy: 0.741\n",
            "Iteration: 86500, Val Loss: 343.184, Val Accuracy: 0.738 Train Loss: 1362.504, Train Accuracy: 0.742\n",
            "Iteration: 87000, Val Loss: 343.194, Val Accuracy: 0.738 Train Loss: 1362.484, Train Accuracy: 0.742\n",
            "Iteration: 87500, Val Loss: 343.181, Val Accuracy: 0.738 Train Loss: 1362.459, Train Accuracy: 0.742\n",
            "Iteration: 88000, Val Loss: 343.178, Val Accuracy: 0.737 Train Loss: 1362.435, Train Accuracy: 0.741\n",
            "Iteration: 88500, Val Loss: 343.204, Val Accuracy: 0.737 Train Loss: 1362.515, Train Accuracy: 0.741\n",
            "Iteration: 89000, Val Loss: 343.186, Val Accuracy: 0.738 Train Loss: 1362.481, Train Accuracy: 0.742\n",
            "Iteration: 89500, Val Loss: 343.190, Val Accuracy: 0.738 Train Loss: 1362.489, Train Accuracy: 0.742\n",
            "Iteration: 90000, Val Loss: 343.186, Val Accuracy: 0.738 Train Loss: 1362.492, Train Accuracy: 0.742\n",
            "Iteration: 90500, Val Loss: 343.164, Val Accuracy: 0.738 Train Loss: 1362.399, Train Accuracy: 0.741\n",
            "Iteration: 91000, Val Loss: 343.202, Val Accuracy: 0.737 Train Loss: 1362.506, Train Accuracy: 0.741\n",
            "Iteration: 91500, Val Loss: 343.178, Val Accuracy: 0.738 Train Loss: 1362.416, Train Accuracy: 0.742\n",
            "Iteration: 92000, Val Loss: 343.188, Val Accuracy: 0.738 Train Loss: 1362.479, Train Accuracy: 0.742\n",
            "Iteration: 92500, Val Loss: 343.175, Val Accuracy: 0.738 Train Loss: 1362.445, Train Accuracy: 0.742\n",
            "Iteration: 93000, Val Loss: 343.207, Val Accuracy: 0.737 Train Loss: 1362.534, Train Accuracy: 0.741\n",
            "Iteration: 93500, Val Loss: 343.161, Val Accuracy: 0.738 Train Loss: 1362.383, Train Accuracy: 0.742\n",
            "Iteration: 94000, Val Loss: 343.182, Val Accuracy: 0.738 Train Loss: 1362.430, Train Accuracy: 0.742\n",
            "Iteration: 94500, Val Loss: 343.172, Val Accuracy: 0.738 Train Loss: 1362.414, Train Accuracy: 0.742\n",
            "Iteration: 95000, Val Loss: 343.199, Val Accuracy: 0.737 Train Loss: 1362.499, Train Accuracy: 0.741\n",
            "Iteration: 95500, Val Loss: 343.179, Val Accuracy: 0.737 Train Loss: 1362.432, Train Accuracy: 0.741\n",
            "Iteration: 96000, Val Loss: 343.160, Val Accuracy: 0.738 Train Loss: 1362.373, Train Accuracy: 0.742\n",
            "Iteration: 96500, Val Loss: 343.169, Val Accuracy: 0.738 Train Loss: 1362.405, Train Accuracy: 0.742\n",
            "Iteration: 97000, Val Loss: 343.173, Val Accuracy: 0.738 Train Loss: 1362.401, Train Accuracy: 0.742\n",
            "Iteration: 97500, Val Loss: 343.185, Val Accuracy: 0.738 Train Loss: 1362.448, Train Accuracy: 0.742\n",
            "Iteration: 98000, Val Loss: 343.182, Val Accuracy: 0.738 Train Loss: 1362.429, Train Accuracy: 0.742\n",
            "Iteration: 98500, Val Loss: 343.155, Val Accuracy: 0.738 Train Loss: 1362.361, Train Accuracy: 0.742\n",
            "Iteration: 99000, Val Loss: 343.166, Val Accuracy: 0.738 Train Loss: 1362.371, Train Accuracy: 0.742\n",
            "Iteration: 99500, Val Loss: 343.178, Val Accuracy: 0.738 Train Loss: 1362.443, Train Accuracy: 0.742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-699686a60e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twLvHA6ztID-",
        "outputId": "3034e3a3-a41f-4647-c6be-22598ca5b014"
      },
      "source": [
        "learning_rate = 0.00001\n",
        "# https://pytorch.org/docs/stable/optim.html\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.95, weight_decay=0.005)\n",
        "#optimizer = torch.optim.ASGD(model.parameters())\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.005, momentum=0.5)\n",
        "#train_dataset = MyDataset(X_train_t, Y_train_t)\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "#test_dataset = MyDataset(X_test_t, Y_test_t)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#val_dataset = MyDataset(X_val_t, Y_val_t)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "for curr_epoch in range(num_epochs):\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = images #Variable(images)\n",
        "        labels = labels #Variable(labels.view(len(labels),1))\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels.reshape(-1, 1))\n",
        "        loss_list_train.append(loss.data)\n",
        "        #print(loss.data)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "        count += 1\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            if count%500 == 0:\n",
        "                # Y_pred = model(X_val_t.to(device))\n",
        "                # loss_val = error(Y_pred, torch.tensor(Y_val_t, dtype=torch.float32).to(device).reshape(-1, 1))\n",
        "                # Y_pred_lab = torch.round(torch.sigmoid(Y_pred))\n",
        "                # accuracy = 1#(Y_pred_lab.cpu() == Y_val_t).sum()/len(Y_val_t)\n",
        "                # Testing the model\n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss_val = 0\n",
        "                for images, labels in val_dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss_val += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                #print(correct, total)\n",
        "                accuracy = correct/total\n",
        "                loss_list_val.append(loss_val.data)\n",
        "                iteration_list_val.append(count)\n",
        "                accuracy_list_val.append(accuracy)\n",
        "                print(\"Iteration: {}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(count, loss_val.data, accuracy), end=\"\")\n",
        "        \n",
        "                total = 0\n",
        "                correct = 0\n",
        "                loss = 0\n",
        "                for images, labels in DataLoader(train_dataset, batch_size=batch_size):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    test = images #.view(batch_size, inp_dim))\n",
        "                    outputs = model(test)\n",
        "                    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "                    predictions = torch.round(torch.sigmoid(outputs)) #torch.max(outputs, 1)[1].to(device)\n",
        "                    correct += (predictions.reshape(-1) == labels).sum().item()\n",
        "                    total += len(labels)\n",
        "                accuracy = correct/total\n",
        "                iteration_list_train.append(count)\n",
        "                loss_train_epoch.append(loss)\n",
        "                accuracy_list_train.append(accuracy)\n",
        "                print(\" Train Loss: {:.3f}, Train Accuracy: {:.3f}\".format(loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 114500, Val Loss: 343.172, Val Accuracy: 0.738 Train Loss: 1362.370, Train Accuracy: 0.742\n",
            "Iteration: 115000, Val Loss: 343.171, Val Accuracy: 0.738 Train Loss: 1362.368, Train Accuracy: 0.742\n",
            "Iteration: 115500, Val Loss: 343.171, Val Accuracy: 0.738 Train Loss: 1362.368, Train Accuracy: 0.742\n",
            "Iteration: 116000, Val Loss: 343.171, Val Accuracy: 0.738 Train Loss: 1362.368, Train Accuracy: 0.742\n",
            "Iteration: 116500, Val Loss: 343.171, Val Accuracy: 0.738 Train Loss: 1362.367, Train Accuracy: 0.742\n",
            "Iteration: 117000, Val Loss: 343.171, Val Accuracy: 0.738 Train Loss: 1362.367, Train Accuracy: 0.742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2gSvA_xGJQw"
      },
      "source": [
        "for param in list(model.children())[0].parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbPPPQmttxTF"
      },
      "source": [
        "with open(data_dir + \"Models/fasttext_cnn.sav\", \"wb\") as f:\n",
        "    pickle.dump(model, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "Gz34Y90-atxH",
        "outputId": "87618076-fd8b-47de-8153-2ec1c5c07604"
      },
      "source": [
        "with open(data_dir + \"Models/fasttext_cnn.sav\", \"rb\") as f:\n",
        "    model = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-cee6c81bfc36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Models/fasttext_cnn.sav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "rxK2yVhmtrQV",
        "outputId": "70b87646-1e24-4813-d46d-37b29d70bd51"
      },
      "source": [
        "loss_train_epoch_m = [i.item() for i in loss_train_epoch]\n",
        "plt.plot([i+1 for i in range(len(iteration_list_train))], loss_train_epoch_m)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Training set Loss-Epoch\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training set Loss-Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "UkpEEeQitrmB",
        "outputId": "bf3647af-33a8-4889-bdfa-13b75dc3a1c4"
      },
      "source": [
        "loss_list_val_m = [i.item() for i in loss_list_val]\n",
        "plt.plot(iteration_list_val, loss_list_val_m)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss over validation\")\n",
        "plt.title(\"Validation set Loss-iteration\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation set Loss-iteration')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xc1Zn/8c+jXm1ZsmzkKlzAAQMGZLBJCCW0ACEkoSUhpC5JSAIpm8JmNyFtf7DZ3fRQUmgpQEgAL4FQTQvF2GBsim1ccZfcZEu2ZUnz/P64R/ZYqIzkGc1I+r5fr/uaO+e2Z+7Y8+jcc+655u6IiIgkU1a6AxARkYFHyUVERJJOyUVERJJOyUVERJJOyUVERJJOyUVERJJOyUWSxszczCaF+RvM7D8SWbcXx/momT3c2zgHEzMbZ2YNZpadxhj0fQ1CpvtcpI2Z/QOY4+7faVf+fuBGYIy7t3SxvQOT3X1pAsdKaF0zqwZWALldHTudzOwaYJK7X9rFOiuBz7j7o30VVydxPAH8wd1/m6L9V5Ph35f0DdVcJN6twKVmZu3KPwb8UT8Wks4akPQvSi4S716gAjixrcDMhgHnAreZ2XFm9pyZbTOz9Wb2SzPL62hHZnaLmf0w7v3XwzbrzOxT7dY9x8xeNrPtZrY61ATaPBVet4XLOzPN7BNm9kzc9ieY2YtmVh9eT4hb9oSZ/cDM/mlmO8zsYTMb3knMw83s/vD5tpjZ02aWFZaNMrO/mlmdma0wsytD+VnAvwEXh/heSeA8xx8z38x+Gs7LujCfn0A83zSzteEzLTaz93Sy/+pwCTLHzH5E9N3+MsT6y7DOFDN7JBxjsZldFLf9LWZ2vZk9YGaNwCmZ8n1JhnN3TZr2TsBvgN/Gvf8sMD/MHwvMAHKAauAN4Mtx6zrR5SGAW4AfhvmzgI3AVKAY+FO7dU8GjiD6Y+fIsO75YVl1WDcn7jifAJ4J8+XAVqLaVQ7w4fC+Iix/AlgGHAIUhvfXdvLZ/x9wA5AbphMBC3HNA74D5AETgOXAmWG7a4guNXV1XlcCp3VQ/n3geWAEUAk8C/ygm3gOBVYDo+LO0cROjrvf+Quf/zNxy4vDvj4Zzt/RwCbgsLjvsR54ZzgPBZnyfWnK7Ek1F2nvVuACMysI7y8LZbj7PHd/3t1b3H0lUTvMSQns8yLgZnd/1d0biX6M93L3J9x9obvH3H0B8OcE9wtwDvCmu98e4vozsAh4X9w6N7v7EnffBdwFTOtkX81AFTDe3Zvd/Wl3d2A6UOnu33f3Pe6+nCgJX5JgjF35KPB9d6919zrge0Q/vF3F0wrkA4eZWa67r3T3Zb08/rnASne/OZy/l4G/AhfGrXOfu/8zfD+7M+j7kgym5CL7cfdniP5yPd/MJgLHEdU0MLNDwmWaDWa2HfhPIJFLFqOI/jpusyp+oZkdb2azwyWneuBzCe63bd+r2pWtAkbHvd8QN78TKOlkXz8GlgIPm9lyM/tWKB8PjAqXp7aZ2TaiS2EjE4yxK+3jXxXKOo3Ho04QXyZK0rVmdoeZjQIIl6LapnEJHH88cHy7z/ZR4KC4deK/u0z6viSDKblIR24jqrFcCjzk7htD+fVEf2VOdvchRD+w7Rv/O7IeGBv3vv2P3p+AWcBYdx9KdCmobb/ddWdcR/QDGW8csDaBuPbj7jvc/WvuPgE4D/hqaMtYDaxw97K4qdTdz04wxp7EPy6UdRUP7v4nd39X2NaB60J5Sdz0Vkcfs9371cCT7T5bibt/vottMuL7ksym5CIduQ04DfgXwiWxoBTYDjSY2RTg8x1s25G7gE+Y2WFmVgR8t93yUmCLu+82s+OAj8QtqwNiRO0cHXkAOMTMPhIarS8GDgPuTzC2vczsXDObZGZG1M7QGo49B9gRGtELzSzbzKaa2fSw6Uaguq2xvQu5ZlYQN+UQXVL6dzOrDA3X3wH+0FU8ZnaomZ0aGv53A7tCnInYyP7n8n6i8/cxM8sN03Qze0cX+8iI70sym5KLvE1oT3mWqLF3VtyifyX6IdlB1OZwZ4L7exD4KfA40WWex9utcgXwfTPbQfTjelfctjuBHwH/DJdtZrTb92aidoOvAZuBbwDnuvumRGJrZzLwKNAAPAf82t1nu3trOMY0ons4NgG/BYaG7f4SXjeb2Utd7P8BokTQNl0D/BCYCywAFgIvhbJO4yFqb7k2xLGBqDPA1Ql+xp8RtaltNbOfu/sO4Ayi9qN1YX/XhWN0JlO+L8lguolSRESSTjUXERFJOiUXERFJOiUXERFJOiUXERFJupx0B3Aghg8f7tXV1ekOQ0SkX5k3b94md69M5TH6dXKprq5m7ty56Q5DRKRfMbP2oyQknS6LiYhI0im5iIhI0im5iIhI0im5iIhI0im5iIhI0im5iIhI0im5iIhI0g3K5DJ35Rau+8ciNCK0iEhqDMrksmBNPdc/sYzNjXvSHYqIyIA0KJNL9fAiAFZtbkxzJCIiA9OgTC7jK4oBWLlpZ5ojEREZmAZlchkzrJAsg1VblFxERFJhUCaX/JxsqoYW6rKYiEiKDMrkAlG7y8rNqrmIiKTCoE0u4yuKVXMREUmRQZtcqiuK2LazmfqdzekORURkwBm0yaWtx9iqLaq9iIgk2yBOLtG9Lmp3ERFJvkGbXMaVhxspN6nmIiKSbIM2uRTl5TBySL7udRERSYFBm1xAPcZERFIlZcnFzArMbI6ZvWJmr5nZ90L5LWa2wszmh2laKDcz+7mZLTWzBWZ2TKpiazO+XPe6iIikQk4K990EnOruDWaWCzxjZg+GZV9397vbrf9eYHKYjgeuD68pUz28mLp5a2hsaqE4P5WnQkRkcElZzcUjDeFtbpi6eoDK+4HbwnbPA2VmVpWq+GBfj7G31O4iIpJUKW1zMbNsM5sP1AKPuPsLYdGPwqWvn5hZfigbDayO23xNKGu/z8vNbK6Zza2rqzug+Krb7nVRu4uISFKlNLm4e6u7TwPGAMeZ2VTgamAKMB0oB77Zw33e5O417l5TWVl5QPGN070uIiIp0Se9xdx9GzAbOMvd14dLX03AzcBxYbW1wNi4zcaEspQZUpBLeXGeai4iIkmWyt5ilWZWFuYLgdOBRW3tKGZmwPnAq2GTWcBlodfYDKDe3denKr424yuKWKWai4hIUqWyi1QVcKuZZRMlsbvc/X4ze9zMKgED5gOfC+s/AJwNLAV2Ap9MYWx7VVcUM2fFlr44lIjIoJGy5OLuC4CjOyg/tZP1HfhCquLpzPiKIu6dv5bdza0U5Gb39eFFRAakQX2HPkTJxR3WbNWlMRGRZFFyCd2RV25SchERSZZBn1z23uuiGylFRJJm0CeXYUW5lBbkqDuyiEgSDfrkYmaMr9AAliIiyTTokwto6H0RkWRTcgGqK4pYu3UXza2xdIciIjIgKLkQ1VxaYs66bbvSHYqIyICg5MK+HmNqdxERSQ4lF/Y910XtLiIiyaHkAowozacgN0sDWIqIJImSC1F35Gr1GBMRSRoll0D3uoiIJI+SSzC+opi3tuwkFvN0hyIi0u8puQTjK4rY0xJjw/bd6Q5FRKTfU3IJ9nVHVruLiMiBUnIJ9nVHVruLiMiBUnIJqoYWkpttqrmIiCSBkkuQnWWMLS/iLdVcREQOmJJLnOqKYnVHFhFJAiWXOOMrili1uRF3dUcWETkQSi5xqiuK2bmnlbqGpnSHIiLSrym5xBmnHmMiIkmh5BKn7V4XJRcRkQOj5BJndFkh2VmmASxFRA6QkkucvJwsRpcVqseYiMgBUnJpp63HmIiI9F7KkouZFZjZHDN7xcxeM7PvtVv+czNriHufb2Z3mtlSM3vBzKpTFVtXouSimouIyIFIZc2lCTjV3Y8CpgFnmdkMADOrAYa1W//TwFZ3nwT8BLguhbF1qrqimPpdzWzbuScdhxcRGRBSllw80lYzyQ2Tm1k28GPgG+02eT9wa5i/G3iPmVmq4uvM+L2jI6v2IiLSWwklFzMbbWYnmNm726YEt8s2s/lALfCIu78AfBGY5e7r260+GlgN4O4tQD1Q0cE+LzezuWY2t66uLpEweqR6770uancREemtnO5WMLPrgIuB14HWUOzAU91t6+6twDQzKwPuCUnpQuDk3gbs7jcBNwHU1NQkfZyWseW6kVJE5EB1m1yA84FD3b3XY6K4+zYzmw2cAkwCloYrXkVmtjS0s6wFxgJrzCwHGAps7u0xe6sgN5uqoQUael9E5AAkcllsOVF7SY+YWWWosWBmhcDpwDx3P8jdq929GtgZEgvALODjYf4C4HFP0wiS6jEmInJgEqm57ATmm9ljRD3AAHD3K7vZrgq4NTTgZwF3ufv9Xaz/O+B2M1sKbAEuSSC2lKiuKObRNzam6/AiIv1eIsllVph6xN0XAEd3s05J3PxuovaYtBtXUcSmhj00NLVQkp/IKRIRkXjd/nK6+61mlgccEooWu3tzasNKr7YBLFduamTq6KFpjkZEpP/pts3FzE4G3gR+BfwaWJJoV+T+6oiQUOat2prmSERE+qdEGvT/BzjD3U9y93cDZxLdQT9gjS0vYsywQp5b1ued1UREBoREkkuuuy9ue+PuS+hF77H+ZsaECl5YsZlYTI88FhHpqUSSy1wz+62ZnRym3wBzUx1Yus2cUMHWnc0s3rgj3aGIiPQ7iSSXzxPdnX9lmF4PZQPajInRyDPPL9elMRGRnuo2ubh7k7v/r7t/MEw/OZC79fuL0WWFjCsvUruLiEgvdNoV2czucveLzGwh0Vhi+3H3I1MaWQaYMaGch17bSCzmZGX1+QDNIiL9Vlf3uVwVXs/ti0Ay0cyJFdw1dw1vbNjO4aN0v4uISKI6vSwWNyT+Fe6+Kn4Cruib8NJrxoS2dpctaY5ERKR/SaRB//QOyt6b7EAyUdXQQqor1O4iItJTXbW5fJ6ohjLBzBbELSoF/pnqwDLFjAkVPLBwPa0xJ1vtLiIiCemq5vIn4H1Eg1a+L2461t0v7YPYMsLMiRVs393CG+u3pzsUEZF+o6s2l3p3X+nuHw7tLLuIeo2VmNm4Poswzfa1u+jSmIhIohIZuPJ9ZvYmsAJ4ElgJPJjiuDLGyCEFTBherHYXEZEeSKRB/4fADGCJux8MvAd4PqVRZZjjJ1QwZ8UWWjXOmIhIQhJJLs3uvhnIMrMsd58N1KQ4rowyc2IFO5paeG1dfbpDERHpFxJJLtvMrAR4Cvijmf0MaExtWJllxsHlgNpdREQSlUhyeT9RY/5XgH8Ay4h6jQ0aI4YUMLFS7S4iIolK5DHH8bWUW1MYS0abMaGC++avo6U1Rk52IjlZRGTw6vRX0sx2mNn2zqa+DDITzJxYQUNTC6+uG3QfXUSkxzqtubh7KYCZ/QBYD9wOGPBRoKpPossgxx+8736XaWPL0hyNiEhmS+T6znnu/mt33+Hu2939eqJ2mEGlsjSfySNK1O4iIpKARJJLo5l91MyyzSzLzD7KIOst1mbGhArmrtxCc2ss3aGIiGS0RJLLR4CLgI1hujCUDTozJ1bQuKeVhWt1v4uISFcS6S22kkF4Gawjx8fd73LMuGFpjkZEJHN1NeT+N9z9v8zsF3T8mOMrUxpZBqooyefQkaU8t2wzV5w8Kd3hiIhkrK5qLm+E17m92bGZFRDd1Z8fjnO3u3/XzH5HNHyMAUuAT7h7g5nlA7cBxwKbgYtDrSmjzJhQzl1z19DcGiNX97uIiHSoq67I/xdee3vjZBNwakgcucAzZvYg8BV33w5gZv8LfBG4Fvg0sNXdJ5nZJcB1wMW9PHbKzJxYwa3PrWLBmm0cO7483eGIiGSkri6L/R8dXA5r4+7ndbVjd3egIbzNDZPHJRYDCuOO8X7gmjB/N/BLM7Own4xx3N77XbYouYiIdKKry2L/faA7N7NsYB4wCfiVu78Qym8GzgZeB74WVh8NrAZw9xYzqwcqgE3t9nk5cDnAuHF9/8yy8uI8phwUtbt84RS1u4iIdKSry2JPHujO3b0VmGZmZcA9ZjbV3V9190+GxPMLoktfN/dgnzcBNwHU1NSkpVYzY0IFd7z4FntaYuTlqN1FRKS9RJ5EOdnM7jaz181sedvUk4O4+zZgNnBWXFkrcAfwoVC0FhgbjpkDDCVq2M84MydWsLs5xitrtqU7FBGRjJTIn903A9cDLcApRD26/tDdRmZWGWosmFkhcDqw2MwmhTIDzgMWhU1mAR8P8xcAj2dae0ubGQdXkJNl/OPVDekORUQkIyWSXArd/THA3H2Vu18DnJPAdlXAbDNbALwIPAL8HbjVzBYCC8M63w/r/w6oMLOlwFeBb/Xok/ShoUW5nH7YSO55eS1NLa3pDkdEJON0e4c+0GRmWcCbZvZFostXJd1t5O4LgKM7WPTOTtbfTTS0TL9w8fSxPPjqBh59vZZzjhx0g0SLiHQpkZrLVUARcCXRDY6Xsu/y1aB14uRKRpcVcseLb6U7FBGRjJNIzaXV3RuI7ln5ZIrj6Teys4wLa8bws8feZPWWnYwtL0p3SCIiGSORmsv/mNkbZvYDM5ua8oj6kQtrxgLwl7mr0xyJiEhm6Ta5uPspRL3E6oAbzWyhmf17yiPrB0aXFfLuyZXcNXcNrbGM7NgmIpIWCd0B6O4b3P3nwOeA+cB3UhpVP3LJ9LFs2L6bp5bUpTsUEZGMkchNlO8ws2tC9+FfAM8CY1IeWT/xnneMpKI4Tw37IiJxEqm5/B7YCpzp7ie7+/XuXpviuPqNvJwsPnTsGB57o5baHbvTHY6ISEZIpM1lprv/zN3X9UVA/dHF08fSEnP+9tLadIciIpIRNOpiEkysLOG46nLufHE1GTpijYhIn1JySZKLp49lxaZGXlixJd2hiIikXZfJxcyyzeyAn+syGJx9RBWl+Tnc+aLueRER6TK5hGHx39VHsfRrhXnZvP/oUTywcD31O5vTHY6ISFolclnsZTObZWYfM7MPtk0pj6wfumT6OJpaYtz3ihr2RWRwSyS5FBA9tOtU4H1hOjeVQfVXU0cPZeroIfx5jhr2RWRw63bgSnfXYJU9cPH0cfzHva+ycG09R44pS3c4IiJpkcgd+oeY2WNm9mp4f6TGFuvceUeNoiA3izvUsC8ig1gil8V+A1wNNMPeh4Bdksqg+rOhhbmcfUQVs+avY+eelnSHIyKSFokklyJ3n9OuTL+aXbhk+jgamlq4f8H6dIciIpIWiSSXTWY2EXAAM7sA0K9mF6ZXD+OQkSXc+OQyDcUvIoNSIsnlC8CNwBQzWwt8mWjofemEmfHV0w9hWV0j97ysbskiMvgkklxWuftpQCUwxd3f5e6rUhxXv3fm4QdxxOih/OSRJTS1tKY7HBGRPpVIcllhZjcBM4CGFMczYJgZ/3rmoazdtktDwojIoJNIcpkCPEp0eWyFmf3SzDQkTALePXk4xx1czi8eX8quPaq9iMjgkcjzXHa6+13u/kHgaGAI8GTKIxsAzIyvn3kodTuauPW5lekOR0SkzyQ05L6ZnWRmvwbmEQ0Hc1FKoxpApleXc8qhlVz/xDK279aAliIyOCRyh/5Koh5iTwNHuPtF7v7XVAc2kHztjEOp39XMb59anu5QRET6RCI1lyPd/QPu/md3b0x5RAPQ1NFDOeeIKn73zAo2NzSlOxwRkZRLJLkMMbN7zKw2TH81szHdbWRmBWY2x8xeMbPXzOx7ofyPZrbYzF41s9+bWW4oNzP7uZktNbMFZnbMAX62jPKV0w9hV3Mr1z+xLN2hiIikXCLJ5WZgFjAqTP8XyrrTBJzq7kcB04CzzGwG8EeiHmhHAIXAZ8L67wUmh+ly4PrEP0bmmzSihA8dM4bbnl/F+vpd6Q5HRCSlEkkule5+s7u3hOkWohsqu+SRtvticsPk7v5AWObAHKCtFvR+4Law6HmgzMyqevyJMthVp03G3fn5Y0vTHYqISEolklw2m9mlZpYdpkuJHh7WrbD+fKAWeMTdX4hblgt8DPhHKBoNxN9tuCaUDRhjhhXxkePGcdfc1azcpOYrERm4EkkunyLqeryBaMDKC4CEHiDm7q3uPo2odnKcmU2NW/xr4Cl3f7onAZvZ5WY218zm1tXV9WTTjPCFUyeRm2385NEl6Q5FRCRlErmJcpW7n+fule4+wt3Pd/e3enIQd98GzAbOAjCz7xJdWvtq3GprgbFx78eEsvb7usnda9y9prKy26tzGWdEaQGffOfBzHplHYs2bE93OCIiKZHQTZS9YWaVZlYW5guB04FFZvYZ4Ezgw+4ei9tkFnBZ6DU2A6h39wE5tP9n3z2BkvwcvnLnK8xbtTXd4YiIJF3KkgtQBcw2swXAi0RtLvcDNwAjgefMbL6ZfSes/wCwHFhK9PTLK1IYW1qVFeXx3xceRd2OJj50/bN89va5LK3VmKAiMnBY1Gmrf6qpqfG5c+emO4xea2xq4ffPrODGp5azq7mVi2rG8uXTJjNySEG6QxORAczM5rl7TSqPkcjwL1eZ2ZBwuep3ZvaSmZ2RyqAGi+L8HL70nsk8+fWT+diM8dw9bzUn/Xg2P35okcYhE5F+LaHeYu6+HTgDGEbUffjalEY1yFSU5HPNeYfz2FdP5szDD+JXs5dx0n/N5o45Peo3ISKSMRJJLhZezwZud/fX4sokicZVFPGzS47m/i+9i8kjSrn6noUsq1NbjIj0P4kkl3lm9jBRcnnIzEqBWDfbyAGYOnoov770GHKzs/iNRlIWkX4okeTyaeBbwHR330k0jEtCN1FK7w0vyefCY8fwt5fWUrt9d7rDERHpkUSSy0xgsbtvC0O//DtQn9qwBOBfTpxASyzGzc+uTHcoIiI9kkhyuR7YaWZHAV8DlgG3pTQqAaB6eDHvnVrFH55fxQ71HhORfiSR5NISRjB+P/BLd/8VUJrasKTNZ0+awI7dLfxZPcdEpB9JJLnsMLOribog/93MsojaXaQPHDmmjBMmVvC7Z1bQ1NKa7nBERBKSSHK5mOjBX59y9w1EA0r+OKVRyX4+d9JENm5v4r7569IdiohIQhIZFXkD0dMjh5rZucBud1ebSx86cfJwDqsawk1PLScW67/D9YjI4JHI8C8XET0x8kKi57q8YGYXpDow2cfM+OxJE1ha28Bji2rTHY6ISLcSuSz2baJ7XD7u7pcBxwH/kdqwpL1zjqhidFkhNz65LN2hiIh0K5HkkuXu8X8ub05wO0minOws/uXEg5m7aitzV25JdzgiIl1KJEn8w8weMrNPmNkngL8TPXtF+thF08cyrCiXG57UkDAiktkSadD/OnATcGSYbnL3b6Y6MHm7orwcLptZzaNvbGRp7Y50hyMi0qmELm+5+1/d/athuifVQUnnPn5CNQW5Wdyo2ouIZLBOk4uZ7TCz7R1MO8xse18GKfuUF+dxcc1Y7p2/lg31GtBSRDJTp8nF3UvdfUgHU6m7D+nLIGV/nzlxAjGH3/9zRbpDERHpkHp99UNjy4s454gq/vTCWyyt1cPERCTzKLn0U18+bTIFuVl86PpnmbNCXZNFJLMoufRTEypLuOeKd1JRkselv32B/3tF446JSOZQcunHxpYX8bfPn8C0sWV86c8vc8OTy4iejiAikl5KLv1cWVEet336ON531CiufXAR/37vq7S0xtIdlogMcjnpDkAOXEFuNj+7eBpjhhVy/RPLWF+/m198+GiK8/X1ikh6qOYyQGRlGd88awo/+sBUnlhcy8U3PUftDt0HIyLpoeQywHz0+PH89uM1LK9r5AO/epb7F6yjWZfJRKSPKbkMQKdOGcmdl88kN9v44p9e5p3XPs5PH11C7XbVZESkb6QsuZhZgZnNMbNXzOw1M/teKP+imS01Mzez4XHrm5n9PCxbYGbHpCq2weCIMUN5/Gsnc/MnpnPYqCH89NE3OeHax/nin17ixZVb1KtMRFIqlS2+TcCp7t5gZrnAM2b2IPBP4H7giXbrvxeYHKbjgevDq/RSVpZxypQRnDJlBCs3NXL786v4y9zV3L9gPe+oGsJlM8fzgaNHU5Cbne5QRWSASVnNxSNtY5Pkhsnd/WV3X9nBJu8HbgvbPQ+UmVlVquIbbKqHF/Mf5x7G8//2Hv7fB4/A3bn6bwv5wK+fZXmdhpARkeRKaZuLmWWb2XygFnjE3V/oYvXRwOq492tCWft9Xm5mc81sbl1dXXIDHgSK8nL48HHjePCqE/nNZTVsqN/F+37xDLN0h7+IJFFKk4u7t7r7NGAMcJyZTU3CPm9y9xp3r6msrDzwIAcpM+P0w0by9ytPZErVEK7888t8+56F7G5uTXdoIjIA9ElvMXffBswGzupitbXA2Lj3Y0KZpNCoskLuuHwGnztpIn984S0+8OtnWbGpMd1hiUg/l8reYpVmVhbmC4HTgUVdbDILuCz0GpsB1Lv7+lTFJ/vkZmfxrfdO4fefqGF9/S7O/fnTGghTRA5IKmsuVcBsM1sAvEjU5nK/mV1pZmuIaiYLzOy3Yf0HgOXAUuA3wBUpjE06cOqUkTxw5YkcelApX9JlMhE5ANaf73eoqanxuXPnpjuMAae5NcZ/P7SYG59azrjyIq58z2TOnzaKnGzdcysyEJjZPHevSeUx9Gshb5ObncXVZ7+D2z99HKUFOfzrX17hjJ88xX3z19Ia679/jIhI31FykU6dOLmS+7/0Lm649Fhys7O46o75vPdnT/HAwvXElGREpAtKLtIlM+OsqQfx4FUn8suPHE1rzLnijy9xzi+e4eHXNmgYGRHpkNpcpEdaY86sV9bys0ffZOXmnUw5qJSLasZy/tGjKS/OS3d4IpKAvmhzUXKRXmlpjXHPy2u5/flVLFhTT2628Z4pI7mwZgwnHVKpxn+RDKbk0g0ll8ywaMN27p67hnvnr2VTwx6Gl+TzwWNGc+GxY5g8sjTd4YlIO0ou3VByySzNrTFmL6rl7nlreHxRLS0x58gxQznz8IM48/CDmDSiJN0highKLt1ScslcmxqauPfltcx6ZR0L1tQDMKGymDMOO4gzDh/JtDFlZGVZmqMUGZyUXLqh5NI/rK/fxaOvb+Th1zfy3LLNtMScEaX5nH7YSN59SCW52cauPTF2Nbeyq57um08AABEiSURBVLmVpuZWdu2J5ptbY5x9RBVHjxuW7o8hMmAouXRDyaX/qd/VzBOLa3n4tY3MXlzLzj2dDy+Tmx3VbJpbnXOOrOKbZ05hXEVRX4UqMmApuXRDyaV/293cymvrtpOdZRTmZlOYm01BXlb0mptNbnYWDU0t3PTkMn7z9ApaYjEum1nNl06dRFmRuj2L9JaSSzeUXAaPjdt3878PL+Ev81ZTkp/Dl06dzGUnjCc/R49oFukpjS0mEowcUsB1FxzJA1edyNHjhvGjB97gPf/zJPfNX6uhaEQykGou0i898+Ym/vOBN3h9/XbKi/M4ZtwwaqqHUTN+GEeMGdptjcbdqdvRxMrNO2mJxTh2/DDVgmTQ0GWxbii5DG6xmPP3het5ckkd81Zt3fsEzbzsLI4YM5Sa8cM4dvwwhhbmsmrzTlZsbmTV5kZWbNrJqs2N+3UmKM7L5t2HVHLaO0ZyypQRGspGBjQll24ouUi8TQ1NzFu1lXmrtjJ35RYWrq2nuXXfv++cLGNceRHVw4sZX1FEdUUx1cOLaW6J8diiWh5ftJGN25vIMjhm3DBOO2wkp71jBBMrSzDTPTkycCi5dEPJRbqyu7mVhWvr2bWnleqKYkaVFXQ55pm78+ra7Tz6xkYefWMjr63bDsCI0nxys7NojTktMSfmTktrjJhDSyxGlhmnHDqCS44byzsnDtfNoZLxlFy6oeQiqbS+fhePvVHLy29tA6KaT3a2kW1GdlY05WQZO5paeHDherbubGbMsEIurhnLhTVjOWhoQZo/gUjHlFy6oeQimaKppZWHXtvInS++xT+XbibLCLWZcZxyaDRKdCzm1DU0sWbrLtZs3cnabbtYu3UX67btYuSQAs4+ooqZEyvI1YjSkmJKLt1QcpFMtGpzI3e+uJq/zFtD3Y4mKkvzKc7LZt223expje237rCiXEaVFbJq804amloYVpTLWVMPihLNhAo9ukBSQsmlG0oukslaWmM8vqiW++avwwxGDytkzLAixpQVMnpYIaPLCinOzwGi9qGnltTx94XrefT1jTTuaaW8OI8zDz+Ic4+s4viDy5VoJGmUXLqh5CID0e7mVp5cUsffF6zn0Tc2snNPK3nZWYwqK2BUWZSURoUENSbMjxxSQG521A6knm3Snb5ILjmp3LmI9FxBbvbeZ+Dsbm7licVRp4K126L2maferKN2RxOd/V2Yk2XkZBs5WVl7X/NzshhfUcTEyhImVhYzcUQJEytLqBpacMDJyN1paGohNzuLgtz03Yi6tXEPxfk55OWohpcJlFxEMlhBbjZnTa3irKlV+5XvaYmxoX43a7btZN223dTtaKKlNUZzzGmNxWhpdZpbnZZYjOZWZ9eeFlZu3sm9L69lR1PL3v0U5WUzobKYCcNLGFqYS35OFvm5WeTnZJOfEyWL/Jws8nKyaGxqoa5hD3U7mtjU0LTfa1NLDDMYO6yIQ0aWMGlEKYeMLGHyiFImjSihMC81Sad+ZzMPvLqee19eywsrtlCQm0XN+HJmTChnxoQKjhxTpmSTJrosJjKIuEc91pbVNrKsriFMjazY1EDD7haaWmLsbm6ls+HazKCiOI/hJflUluYzvCSf4SXR+93NMZbU7uDNjTtYsalx7w2sZjBmWCGHjChl0sgSDhlRyiEje590dje38viiWu59eS1PLK5jT2uMCZXFnHvkKLbvaub55ZtZtGEHAIW52dRUD2PGhApmTKhg6ughGuYHtbl0S8lFJDVaWmM0tbRNrTQ1xyjKz6a8KC+hjgXNrTFWbW7kzY0NLNnYwJu1O3hzYwPLNzXsl3TiazoThheTn5u19/6hnKwssrOj+ewsY3dzK/94dQMPLtzAjqYWKkvzOe+oUZw/bTRTRw/Z7/LelsY9zFmxmeeXb9kv2WSHURomVpYwcUQxkypLmDiihEkjShhSkJuak5mBlFy6oeQi0r9ESWcnb27cwZKNDR3WdLpSkp/DmYcfxPlHj+KEicPJTnA0hM0NTcxZsYXX129nWV0DS2sb3nbMEaX5jK8oorI0n8qS/P1qZ5Wl+QwvzackL4etO/ewuXEPWxr3sLWxbb6JzY172L6rhYLcLErycyjKy6E4P3v/17xsKkrymVhZzI7dLVQPL+71uTwQ/Tq5mFkB8BSQT9S2c7e7f9fMDgbuACqAecDH3H2PmeUDtwHHApuBi919ZVfHUHIRGRiaW6M2pObW2N5hdlpCm1HbPMC0sWVJa79paY2xeusultY27E04q7fsZFNDE5sa9lC/qznhfRXkZlFRnE9pQQ57WmI07mlhZ1MrjXtaOr3ECPDKd89gaGHf15j6e2+xJuBUd28ws1zgGTN7EPgq8BN3v8PMbgA+DVwfXre6+yQzuwS4Drg4hfGJSIbIzc5ibHnfPsI6JzuLg4cXc/DwYk5n5NuWN7W0sqlhD5t2RJ0W6hqaaGxqYVhRHuUleZQX5VFenEdFSR5FeR3/lLo7u5v3JZuGphY+fvMc6nY0AfDr2Uu56rTJFOZmD7gu5H1yWczMioBngM8DfwcOcvcWM5sJXOPuZ5rZQ2H+OTPLATYAld5FgKq5iEh/87+PLOGGJ5Zx/IRynn5zEwAnTKzY+5iHI0YP5dCDSjlm/DAee2Mjw0vyaYk5ZYW5NDa18s5JFQeciPp7zQUzyya69DUJ+BWwDNjm7m19IdcAo8P8aGA1QEg89USXzja12+flwOUA48aNS2X4IiJJ96VTJ3HhsWOoLM3nu/e9BsCzyzexoX43LTHn/gXru9x+WFEuWWZcffY7uODYMX0Rcq+kNLm4eyswzczKgHuAKUnY503ATRDVXA50fyIifSn+EuB1Fxz5tuVvhQfbvbq2nkkjSnhp1VYmVBazp9XJz85i/pptGDB2WGEfR94zfXITpbtvM7PZwEygzMxyQu1lDLA2rLYWGAusCZfFhhI17IuIDBrjKooYV1HESYdUAnDm4Qftt/yi6WPTEVaPpezWVTOrDDUWzKwQOB14A5gNXBBW+zhwX5ifFd4Tlj/eVXuLiIhkrlTWXKqAW0O7SxZwl7vfb2avA3eY2Q+Bl4HfhfV/B9xuZkuBLcAlKYxNRERSKGXJxd0XAEd3UL4cOK6D8t3AhamKR0RE+o5GdBMRkaRTchERkaRTchERkaRTchERkaRTchERkaTr10Pum1kdsKqTxcNpN3RMBlKMyaEYk0MxHrhMjw+iGIvdvTKVB+nXyaUrZjY31QOzHSjFmByKMTkU44HL9Pig72LUZTEREUk6JRcREUm6gZxcbkp3AAlQjMmhGJNDMR64TI8P+ijGAdvmIiIi6TOQay4iIpImSi4iIpJ87j7gJuAsYDGwFPhWHxxvJbAQmA/MDWXlwCPAm+F1WCg34OchtgXAMXH7+XhY/03g43Hlx4b9Lw3bWgIx/R6oBV6NK0t5TJ0dowcxXkP04Lj5YTo7btnV4XiLgTO7+76Bg4EXQvmdQF4ozw/vl4bl1V3EOJboGUSvA68BV2Xauewixow5l0ABMAd4JcT4vd7uN1mxJxjfLcCKuHM4LZ3/Z8L62USPK7k/k87h2+Ls7Q9qpk7hxC8DJgB54R/LYSk+5kpgeLuy/2r7coBvAdeF+bOBB8M/zhnAC3H/wJaH12Fhvu0Ha05Y18K2700gpncDx7D/D3fKY+rsGD2I8RrgXztY97DwXeaHf+jLwnfd6fcN3AVcEuZvAD4f5q8AbgjzlwB3dhFjFeGHAygFloRYMuZcdhFjxpzL8NlKwnwu0Q/VjJ7uN5mxJxjfLcAFHayflv8zYZ2vAn9iX3LJiHP4tjgP5Ec1EyeiRyk/FPf+auDqFB9zJW9PLouBqjBfBSwO8zcCH26/HvBh4Ma48htDWRWwKK58v/W6iaua/X+4Ux5TZ8foQYzX0PEP4n7fI/BQ+K47/L7Df+BNQE77fxdt24b5nLBet7XBsP59RE9Vzbhz2UGMGXkugSLgJeD4nu43mbEnGN8tdJxc0vI9Ez0a/jHgVOD+3nw3fXEO3X1AtrmMBlbHvV8TylLJgYfNbJ6ZXR7KRrr7+jC/ARjZTXxdla/poLw3+iKmzo7RE180swVm9nszG9bLGCuAbe7e0kGMe7cJy+vD+l0ys2qiB+C9QIaey3YxQgadSzPLNrP5RJdCHyH6K7mn+01m7F3G5+5t5/BH4Rz+xMzy28eXYBzJ+p5/CnwDiIX3vfluUnYO4w3E5JIO73L3Y4D3Al8ws3fHL/Qo3XtaIutEX8TUy2NcD0wEpgHrgf9Jdly9YWYlwF+BL7v79vhlmXIuO4gxo86lu7e6+zSiv76PA6akM5722sdnZlOJ/nKfAkwnutT1zRTH0On3bGbnArXuPi+VMSTLQEwua4kaONuMCWUp4+5rw2stcA/Rf5yNZlYFEF5ru4mvq/IxHZT3Rl/E1NkxEuLuG8N/8hjwG/Y9ErunMW4Gyswsp135fvsKy4eG9TtkZrlEP9p/dPe/dfM503IuO4oxE89liGsbUQeEmb3YbzJj7y6+s9x9vUeagJvp/TlMxvf8TuA8M1sJ3EF0aexnXXy+tJ1DYEC2ueQQNaIdzL5GqcNTeLxioDRu/lmiHhc/Zv9Guv8K8+ewf0PgnFBeTtQrZViYVgDlYVn7hsCzE4ytmv3bM1IeU2fH6EGMVXHzXwHuCPOHs38j5HKiBshOv2/gL+zfCHlFmP8C+zd03tVFfAbcBvy0XXnGnMsuYsyYcwlUAmVhvhB4Gji3p/tNZuwJxlcVd45/Clyb7v8zYb2T2degnxHn8G0x9vZHNZMnop4cS4iu6X47xceaEL6Eti6M3w7lFUQNb28Cj8b9AzPgVyG2hUBN3L4+RdTVbynwybjyGuDVsM0vSawr8p+JLoU0E10j/XRfxNTZMXoQ4+0hhgXALPb/gfx2ON5i4nrMdfZ9h+9mToj9L0B+KC8I75eG5RO6iPFdRJcpFhDXpTeTzmUXMWbMuQSOJOo+uyB81u/0dr/Jij3B+B4P5/BV4A/s61GWlv8zcfs6mX3JJSPOYftJw7+IiEjSDcQ2FxERSTMlFxERSTolFxERSTolFxERSTolFxERSTolFxnUzOzZ8FptZh9J8r7/raNjiQwG6oosApjZyUSDPJ7bg21yfN94Sx0tb3D3kmTEJ9LfqOYig5qZNYTZa4ETzWy+mX0lDGL4YzN7MQxa+Nmw/slm9rSZzSJ6fgpmdm8YtPS1toFLzexaoDDs74/xx7LIj83sVTNbaGYXx+37CTO728wWmdkfzcza9mdmr4dY/rsvz5FIb+R0v4rIoPAt4mouIUnUu/v0MBLuP83s4bDuMcBUd18R3n/K3beYWSHwopn91d2/ZWZf9GggxPY+SDSY5FHA8LDNU2HZ0UTDc6wD/gm808zeAD4ATHF3N7OypH96kSRTzUWkY2cAl4Uh2F8gGqJjclg2Jy6xAFxpZq8AzxMN/DeZrr0L+LNHg0puBJ4kGnW3bd9rPBpscj7R2Gv1wG7gd2b2QWDnAX86kRRTchHpmAFfcvdpYTrY3dtqLo17V4raak4jeijTUUTjUxUcwHGb4uZbiR7Q1EI0Gu/dRIMp/uMA9i/SJ5RcRCI7iB4R3OYh4PNhKHvM7BAzK+5gu6HAVnffaWZTiEa9bdPctn07TwMXh3adSqLHPc/pLLDwnJah7v4A0ejGR/Xkg4mkg9pcRCILgNZweesWoudkVAMvhUb1OuD8Drb7B/C50C6ymOjSWJubgAVm9pK7fzSu/B6iZ5m8QjSa8TfcfUNITh0pBe4zswKiGtVXe/cRRfqOuiKLiEjS6bKYiIgknZKLiIgknZKLiIgknZKLiIgknZKLiIgknZKLiIgknZKLiIgk3f8H/s7Y04icF1gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "EIy1g1xettG-",
        "outputId": "20172aa7-83d2-400b-cd36-93fba8482a71"
      },
      "source": [
        "accuracy_list_val_m = [i for i in accuracy_list_val]\n",
        "plt.plot(iteration_list_val, accuracy_list_val_m)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Validation set Accuracy-iteration\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation set Accuracy-iteration')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "BoSogOtptuZC",
        "outputId": "3a92c913-fe58-485d-987b-fa0950016cf6"
      },
      "source": [
        "accuracy_list_train_m = [i for i in accuracy_list_train]\n",
        "plt.plot(iteration_list_train, accuracy_list_train_m)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.title(\"Training set Accuracy-iteration\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training set Accuracy-iteration')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "aKSGSGBItvt4",
        "outputId": "7341900b-04f6-42d5-d2c0-305b37c336de"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "loss = 0\n",
        "predictions_l = []\n",
        "labels_l = []\n",
        "probas_l = []\n",
        "for images, labels in test_dataloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    test = images #.view(batch_size, inp_dim))\n",
        "    outputs = model(test)\n",
        "    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "    proba = torch.sigmoid(outputs).reshape(-1)\n",
        "    probas_l.append(proba)\n",
        "    predictions = torch.round(torch.sigmoid(outputs)).reshape(-1) #torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum().item()\n",
        "    predictions_l.append(predictions)\n",
        "    labels_l.append(labels)\n",
        "    total += len(labels)\n",
        "accuracy = correct/total \n",
        "print(\"Test Accuracy: {}, Test Loss: {}\".format(accuracy, loss))\n",
        "print(\"Test Confusion Matrix\")\n",
        "y_true = torch.cat(labels_l, dim=0).detach().cpu()\n",
        "y_pred = torch.cat(predictions_l, dim=0).detach().cpu()\n",
        "y_proba = torch.cat(probas_l, dim=0).detach().cpu()\n",
        "roc_auc_sc = roc_auc_score(y_true, y_proba)\n",
        "print(\"Test AUC: \", roc_auc_sc)\n",
        "fpr, tpr, threshold = roc_curve(y_true, y_proba)\n",
        "plt.title('Test ROC')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_sc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "print(classification_report(y_true, y_pred))\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='small')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-ed1238b7ac1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-7b4c1a0566f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 14.76 GiB total capacity; 12.16 GiB already allocated; 3.75 MiB free; 13.72 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "o1Q9AoHlt3OP",
        "outputId": "69346146-f1f2-44d3-d114-c4926dd89d59"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "loss = 0\n",
        "predictions_l = []\n",
        "labels_l = []\n",
        "probas_l = []\n",
        "for images, labels in DataLoader(val_dataset, batch_size=batch_size):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    test = images #.view(batch_size, inp_dim))\n",
        "    outputs = model(test)\n",
        "    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "    proba = torch.sigmoid(outputs).reshape(-1)\n",
        "    probas_l.append(proba)\n",
        "    predictions = torch.round(torch.sigmoid(outputs)).reshape(-1) #torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum().item()\n",
        "    predictions_l.append(predictions)\n",
        "    labels_l.append(labels)\n",
        "    total += len(labels)\n",
        "accuracy = correct/total \n",
        "print(\"Val Accuracy: {}, Val Loss: {}\".format(accuracy, loss))\n",
        "print(\"Val Confusion Matrix\")\n",
        "y_true = torch.cat(labels_l, dim=0).detach().cpu()\n",
        "y_pred = torch.cat(predictions_l, dim=0).detach().cpu()\n",
        "y_proba = torch.cat(probas_l, dim=0).detach().cpu()\n",
        "roc_auc_sc = roc_auc_score(y_true, y_proba)\n",
        "print(\"Val AUC: \", roc_auc_sc)\n",
        "fpr, tpr, threshold = roc_curve(y_true, y_proba)\n",
        "plt.title('Val ROC')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_sc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "print(classification_report(y_true, y_pred))\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='small')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Accuracy: 0.7947037271785675, Val Loss: 285.34405517578125\n",
            "Val Confusion Matrix\n",
            "Val AUC:  0.8633649994920023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.88      0.84     40881\n",
            "         1.0       0.76      0.65      0.70     23806\n",
            "\n",
            "    accuracy                           0.79     64687\n",
            "   macro avg       0.78      0.76      0.77     64687\n",
            "weighted avg       0.79      0.79      0.79     64687\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjz7dTU9098I",
        "outputId": "32c9a7cf-560d-414a-d7af-3d08a1ef8bad"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "#del model\n",
        "#del train_dataloader, test_dataloader, val_dataloader\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "bTlQDLOSt4vN",
        "outputId": "e21e5ea7-f4c9-419b-9aa1-e5a40744781f"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "loss = 0\n",
        "predictions_l = []\n",
        "labels_l = []\n",
        "probas_l = []\n",
        "for images, labels in DataLoader(train_dataset, batch_size=100):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    test = images #.view(batch_size, inp_dim))\n",
        "    outputs = model(test)\n",
        "    loss += error(outputs, labels.reshape(-1, 1)).data\n",
        "    proba = torch.sigmoid(outputs).reshape(-1)\n",
        "    probas_l.append(proba)\n",
        "    predictions = torch.round(torch.sigmoid(outputs)).reshape(-1) #torch.max(outputs, 1)[1].to(device)\n",
        "    correct += (predictions == labels).sum().item()\n",
        "    predictions_l.append(predictions)\n",
        "    labels_l.append(labels)\n",
        "    total += len(labels)\n",
        "accuracy = correct/total \n",
        "print(\"Train Accuracy: {}, Train Loss: {}\".format(accuracy, loss))\n",
        "print(\"Train Confusion Matrix\")\n",
        "y_true = torch.cat(labels_l, dim=0).detach().cpu()\n",
        "y_pred = torch.cat(predictions_l, dim=0).detach().cpu()\n",
        "y_proba = torch.cat(probas_l, dim=0).detach().cpu()\n",
        "roc_auc_sc = roc_auc_score(y_true, y_proba)\n",
        "print(\"Train AUC: \", roc_auc_sc)\n",
        "fpr, tpr, threshold = roc_curve(y_true, y_proba)\n",
        "plt.title('Train ROC')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_sc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "print(classification_report(y_true, y_pred))\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='small')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-98a1dd35a313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-28696d9e7206>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-28696d9e7206>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx_conv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv1d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Max pooling. Output shape: (b, num_filters[i], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    259\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 260\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.66 GiB already allocated; 19.75 MiB free; 13.71 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "c2K9zeUdt98L",
        "outputId": "327e8033-79d3-4a16-9927-fb790c183e37"
      },
      "source": [
        "interm_model = nn.Sequential(*list(model.children())[:-1])\n",
        "total = 0\n",
        "correct = 0\n",
        "loss = 0\n",
        "out = []\n",
        "labels_l = []\n",
        "for images, labels in DataLoader(val_dataset, batch_size=batch_size):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    test = images #.view(batch_size, inp_dim))\n",
        "    outputs = interm_model(test)\n",
        "    labels_l.append(labels)\n",
        "    out.append(outputs)\n",
        "\n",
        "class pca:\n",
        "    def __init__(self, n_components):\n",
        "        \"\"\"\n",
        "        :param n_components: Number of principal components the data should be reduced too.\n",
        "        \"\"\"\n",
        "        self.components = n_components\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"\n",
        "        * Centering our inputs with mean\n",
        "        * Finding covariance matrix using centered tensor\n",
        "        * Finding eigen value and eigen vector using torch.eig()\n",
        "        * Sorting eigen values in descending order and finding index of high eigen values\n",
        "        * Using sorted index, get the eigen vectors\n",
        "        * Tranforming the Input vectors with n columns into PCA components with reduced dimension\n",
        "        :param X: Input tensor with n columns.\n",
        "        :return: Output tensor with reduced principal components\n",
        "        \"\"\"\n",
        "        centering_X = X - torch.mean(X, dim=0)\n",
        "        covariance_matrix = torch.mm(centering_X.T, centering_X)/(centering_X.shape[0] - 1)\n",
        "        eigen_values, eigen_vectors = torch.eig(covariance_matrix, eigenvectors=True)\n",
        "        eigen_sorted_index = torch.argsort(eigen_values[:,0],descending=True)\n",
        "        eigen_vectors_sorted = eigen_vectors[:,eigen_sorted_index]\n",
        "        component_vector = eigen_vectors_sorted[:,0:self.components]\n",
        "        transformed = torch.mm(component_vector.T, centering_X.T).T\n",
        "        return transformed\n",
        "pca_out = pca(n_components=2).fit_transform(torch.cat(out))\n",
        "pca_vector = pca_out\n",
        "plt.figure(figsize=(12, 12))\n",
        "sb.scatterplot(\n",
        "    pca_vector[:, 0].detach().cpu(), \n",
        "    pca_vector[:, 1].detach().cpu(), \n",
        "    hue=torch.cat(labels_l).detach().cpu(), \n",
        "    #s=100, \n",
        "    palette=\"tab10\"\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-39807cf3b6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;31m#.view(batch_size, inp_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlabels_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    }
  ]
}